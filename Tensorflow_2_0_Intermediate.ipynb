{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow 2.0 Intermediate",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "p0JofRx2if_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "8f494398-36db-41d9-9a34-c53384396b08"
      },
      "cell_type": "code",
      "source": [
        "! pip install tensorflow-gpu==2.0.0.alpha0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0.alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.33.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.9)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.16.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (40.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "2.0.0-alpha0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BGLE7fm1l5pG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQQkVrGOhgkD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TFRecords\n",
        "Because a TFRecord file is a sequence of binary strings, its structure must be specified prior to saving so that it can be properly written and subsequently read back. TensorFlow has two structures for this, tf.train.Example and tf.train.SequenceExample. What you have to do is store each sample of your data in one of these structures, then serialize it, and use tf.python_io.TFRecordWriter to save it to disk.\n",
        "\n",
        "Here, the float array, data, is converted to the binary format and then saved to disc. \n",
        "A feature is a dictionary containing the data that is passed to tf.train.Example prior to serialization and saving."
      ]
    },
    {
      "metadata": {
        "id": "K3fr0ICFhcN2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "data=np.array([10.,11.,12.,13.,14.,15.])\n",
        "\n",
        "def npy_to_tfrecords(fname,data):\n",
        "    writer = tf.io.TFRecordWriter(fname)\n",
        "    feature={}\n",
        "    feature['data'] = tf.train.Feature(float_list=tf.train.FloatList(value=data))\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    serialized = example.SerializeToString()\n",
        "    writer.write(serialized)\n",
        "    writer.close()\n",
        "\n",
        "npy_to_tfrecords(\"./myfile.tfrecords\",data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NoZ2zIaChsCs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code to read the record back is as follows. A parse_function function is constructed that decodes the dataset read back from the file. This requires a dictionary (keys_to_features) with the same name and structure as the saved data:"
      ]
    },
    {
      "metadata": {
        "id": "TBTQj0vYhs6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TFRecordDataset(\"./myfile.tfrecords\")\n",
        "\n",
        "def parse_function(example_proto):\n",
        " keys_to_features = {'data':tf.io.FixedLenSequenceFeature([], dtype = tf.float32, allow_missing = True) }\n",
        "    parsed_features = tf.io.parse_single_example(serialized=example_proto, features=keys_to_features)\n",
        "    return parsed_features['data']\n",
        "\n",
        "dataset = dataset.map(parse_function)\n",
        "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
        "# array is retrieved as one item\n",
        "item = iterator.get_next()\n",
        "print(item)\n",
        "print(item.numpy())\n",
        "print(item[2].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0EKLDynhwho",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A more complex use-case:"
      ]
    },
    {
      "metadata": {
        "id": "aDtiBhjah0tb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = './students.tfrecords'\n",
        "data = {\n",
        "            'ID': 61553,\n",
        "            'Name': ['Jones', 'Felicity'],\n",
        "            'Scores': [45.6, 97.2] \n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuFT01Iih57f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using this, we can construct a tf.train.Example class, again using the Feature() method. Note how we have to encode our string:\n",
        "\n",
        "ID = tf.train.Feature(int64_list=tf.train.Int64List(value=[data['ID']]))\n",
        "\n",
        "Name = tf.train.Feature(bytes_list=tf.train.BytesList(value=[n.encode('utf-8') for n in data['Name']]))\n",
        "\n",
        "Scores = tf.train.Feature(float_list=tf.train.FloatList(value=data['Scores']))\n",
        "\n",
        "example = tf.train.Example(features=tf.train.Features(feature={'ID': ID, 'Name': Name, 'Scores': Scores }))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JSYSatgmiIRI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Serializing and writing this record to disc is the same as TFRecord example 1:\n",
        "\n",
        "writer = tf.io.TFRecordWriter(filename)\n",
        "writer.write(example.SerializeToString())\n",
        "writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nj1We2k_iMYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# To read this back, we just need to construct our parse_function function to reflect the structure of the record:\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(\"./students.tfrecords\")\n",
        "\n",
        "def parse_function(example_proto):\n",
        "    keys_to_features = {'ID':tf.io.FixedLenFeature([], dtype = tf.int64),\n",
        "                       'Name':tf.io.VarLenFeature(dtype = tf.string),\n",
        "                        'Scores':tf.io.VarLenFeature(dtype = tf.float32)\n",
        "                       }\n",
        "    parsed_features = tf.io.parse_single_example(serialized=example_proto, features=keys_to_features)\n",
        "    return parsed_features[\"ID\"], parsed_features[\"Name\"],parsed_features[\"Scores\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ph2qFbuFiQCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(parse_function)\n",
        "\n",
        "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
        "item = iterator.get_next()\n",
        "# record is retrieved as one item\n",
        "print(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zhYOoaTvia3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can extract our data from item (note that the string must be decoded (from bytes) where the default for our Python 3 is utf8). Note also that the string and the array of floats are returned as sparse arrays, and to extract them from the record, we use the sparse array value method:"
      ]
    },
    {
      "metadata": {
        "id": "GHIDftufibUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"ID: \",item[0].numpy())\n",
        "name = item[1].values.numpy()\n",
        "name1= name[0].decode()returned\n",
        "name2 = name[1].decode('utf8')\n",
        "print(\"Name:\",name1,\",\",name2)\n",
        "print(\"Scores: \",item[2].values.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}