{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet-CLR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EveNtgMncRry"
      },
      "source": [
        "## Tiny ImageNet Challenge -  EIP 3.0\n",
        "\n",
        "---\n",
        "\n",
        "### There are few utility functions first up to load the data and set up the generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7F31RIiVkxz",
        "colab_type": "code",
        "outputId": "a223c833-2634-43b6-8c52-84bdf20e1e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxMQ0DMAc2vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip -q '/content/drive/My Drive/tiny-imagenet-200.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hX-oJ9IPKCd",
        "colab_type": "code",
        "outputId": "81fde949-8d93-4a25-fc56-a5a6f7ff071e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Assignment\\ 4/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Assignment 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR3xDzmgirIG",
        "colab_type": "code",
        "outputId": "9242967a-b5ca-496c-aadc-f6043ed924c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.models import load_model\n",
        "import keras.backend as K\n",
        "import json\n",
        "import sys\n",
        "\n",
        "\n",
        "TRAIN = \"/content/tiny-imagenet-200/train/\"\n",
        "VAL = \"/content/tiny-imagenet-200/val/images\"\n",
        "VAL_ANNOT = \"/content/tiny-imagenet-200/val/val_annotations.txt\"\n",
        "WORDNET = \"/content/tiny-imagenet-200/wnits.txt\"\n",
        "WORD_LABELS = \"/content/tiny-imagenet-200/words.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPDuzFRmkVlv",
        "colab_type": "text"
      },
      "source": [
        "## Used 10 types of image augmentations as specified in the comments\n",
        "\n",
        "---\n",
        "\n",
        "1. Rotation Angle\n",
        "2. Zoom Range\n",
        "3. Width Shift\n",
        "- Height Shift\n",
        "- Shear Range\n",
        "-  Horizontal Flip\n",
        "-  Fills empty with reflections\n",
        "- Increasing/decreasing brightness\n",
        "-  Pepper augmentation (The size percent makes it similar to Cutout/Occlusion)\n",
        "- CoarseSaltAndPepper augmentations (imgaug)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eBBK3X1_9jf",
        "colab_type": "code",
        "outputId": "4e287ddd-d4ad-4fdd-a28e-fda804766f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "val_data = pd.read_csv(VAL_ANNOT , sep='\\t', names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X','Y','H', 'W'], axis=1, inplace=True)\n",
        "\n",
        "# Augmentations to be include: Increased Contrast, Random Erasing/Cutout/Occlusion, SalandPepper Noise (Prevents Overfitting)\n",
        "seq = iaa.Sequential([iaa.Pepper(0.02), iaa.CoarseSaltAndPepper(size_percent=0.1)])\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=18, # Rotation Angle\n",
        "        zoom_range=0.15,  # Zoom Range\n",
        "        width_shift_range=0.2, # Width Shift\n",
        "        height_shift_range=0.2, # Height Shift\n",
        "        shear_range=0.15,  # Shear Range\n",
        "        horizontal_flip=True, # Horizontal Flip\n",
        "        fill_mode=\"reflect\", # Fills empty with reflections\n",
        "        brightness_range=[0.4, 1.6],  # Increasing/decreasing brightness\n",
        "        preprocessing_function=(seq.augment_image)   # Pepper and CoarseSaltAndPepper augmentations\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        TRAIN,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=128,\n",
        "        class_mode='categorical')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_data, directory=VAL, \n",
        "    x_col='File', \n",
        "    y_col='Class', \n",
        "    target_size=(64, 64),\n",
        "    color_mode='rgb', \n",
        "    class_mode='categorical', \n",
        "    batch_size=128, \n",
        "    shuffle=False, \n",
        "    seed=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6SkqZkPcqMJ",
        "colab_type": "text"
      },
      "source": [
        "## Custom layered ResNet that uses Pre-Activated Layers and BottleNeck Blocks with SeparableConv2D\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "-  The reason to use 1x1 to increase the number of channels is to create a wider model with minimum increase in trainable parameters\n",
        "- I initially replaced stride by 2 in the shortcut connections with AveragePooling2D but saw a performance drop and so reverted back (Trained from scratch again!)\n",
        "- Uses SeparableConv2D rather than vanilla Conv2D and this drastically reduced the number of parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgq6Gz9inSJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, SeparableConv2D\n",
        "from keras.layers.convolutional import AveragePooling2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.core import Activation\n",
        "from CyclicLearningRate.clr_callback import *\n",
        "from keras.layers import Flatten, Input, add\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import *\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "class ResNet:\n",
        "\t@staticmethod\n",
        "\tdef residual_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "\t\tshortcut = data\n",
        "\n",
        "\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
        "\t\tact1 = Activation(\"relu\")(bn1)\n",
        "\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
        "\t\tact2 = Activation(\"relu\")(bn2)\n",
        "\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride, padding=\"same\", use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
        "\n",
        "\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
        "\t\tact3 = Activation(\"relu\")(bn3)\n",
        "\t\tconv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
        "\n",
        "\t\tif red:\n",
        "\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\tx = add([conv3, shortcut])\n",
        "\n",
        "\t\treturn x\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\tinputs = Input(shape=inputShape)\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(inputs)\n",
        "\n",
        "\t\tx = Conv2D(filters[0], (5, 5), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\t\tx = ZeroPadding2D((1, 1))(x)\n",
        "\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    \n",
        "\t\tfor i in range(0, len(stages)):\n",
        "\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n",
        "\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\t\tfor j in range(0, stages[i] - 1):\n",
        "\t\t\t\tx = ResNet.residual_module(x, filters[i + 1], (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\t\tx = AveragePooling2D((8, 8))(x)\n",
        "  \n",
        "\t\tx = Conv2D(200, (1,1), kernel_regularizer=l2(reg))(x)\n",
        "\t\tx = Flatten()(x)\n",
        "\t\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t\tmodel = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "\t\treturn model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mld7rEyHndRm",
        "colab_type": "code",
        "outputId": "300158b9-8e68-4c06-e166-4ca4ee8f5e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "model = ResNet.build(64, 64, 3, 200, (3, 4, 6), (64, 128, 256, 512), reg=0.0005)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIHldgu6eUFL",
        "colab_type": "text"
      },
      "source": [
        "## Custom callback to save after every 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtnqmZVhqGWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "class EpochCheckpoint(Callback):\n",
        "\tdef __init__(self, outputPath, every=5, startAt=0):\n",
        "\t\t# call the parent constructor\n",
        "\t\tsuper(Callback, self).__init__()\n",
        "    \n",
        "\t\tself.outputPath = outputPath\n",
        "\t\tself.every = every\n",
        "\t\tself.intEpoch = startAt\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\t# check to see if the model should be serialized to disk\n",
        "\t\tif (self.intEpoch + 1) % self.every == 0:\n",
        "\t\t\tp = os.path.sep.join([self.outputPath,\n",
        "\t\t\t\t\"resnet.hdf5\".format(self.intEpoch + 1)])\n",
        "\t\t\tself.model.save(p, overwrite=True)\n",
        "\t\tself.intEpoch += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUS5iiFMeiQj",
        "colab_type": "text"
      },
      "source": [
        "## Custom Learning Rate Decay callback\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Used to train smaller batch sizes and decaying LR to find a better convergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ck0DWXBsKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learning Rate Decay\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "NUM_EPOCHS = 35\n",
        "INIT_LR = 0.0000002\n",
        "\n",
        "def poly_decay(epoch):\n",
        "  maxEpochs = NUM_EPOCHS\n",
        "  baseLR = INIT_LR\n",
        "  power = 1.0\n",
        "  \n",
        "  # compute the new learning rate based on polynomial decay\n",
        "  alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
        "  \n",
        "  # return the new learning rate\n",
        "  return alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOwSFCk6fcQp",
        "colab_type": "text"
      },
      "source": [
        "## Cyclic Learning Rate to train larger batch sizes for the first 100 Epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSuy9JhqtRjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "flag = 0\n",
        "\n",
        "checkpoint_path = \"../checkpoints/check.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create checkpoint callback\n",
        "\n",
        "cp_callback = tensorflow.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                 save_weights_only=False,\n",
        "                                                 verbose=1, period=5)\n",
        "# Cyclic Learning Rate\n",
        "clr_triangular = CyclicLR(mode='triangular', max_lr=0.1)\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "  EpochCheckpoint('../checkpoints/', every=1),\n",
        "   cp_callback,\n",
        "    LearningRateScheduler(poly_decay)   \n",
        "]\n",
        "# clr_triangular"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RALOv_sFfqNo",
        "colab_type": "text"
      },
      "source": [
        "## Model Summary (Params much lesser than 26M)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Total params: 2,265,748\n",
        "### Trainable params: 2,252,046\n",
        "### Non-trainable params: 13,702"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_POn-Gf-Gapj",
        "colab_type": "code",
        "outputId": "ddb77098-2cdb-459b-9115-9ea4017a58a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5563
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "if flag == 0: \n",
        "  model = ResNet.build(64, 64, 3, 200, (3, 4, 6), (64, 128, 256, 512), reg=0.0005)\n",
        "  opt = SGD(lr=INIT_LR, momentum=0.9)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#   model.compile(optimizer=Adam(0.1), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "else:\n",
        "  \n",
        "  # Load the model\n",
        "  model = load_model('../checkpoints/resnet.hdf5')\n",
        "  \n",
        "#   Update the learning rate\n",
        "  print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "  K.set_value(model.optimizer.lr, le-3)\n",
        "  print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 3)    12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 64)   4800        batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 32)   2048        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9216        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 128)  4096        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 128)  8192        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 128)  0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   4096        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9216        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 128)  4096        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 128)  0           conv2d_8[0][0]                   \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   4096        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9216        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  4096        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           conv2d_11[0][0]                  \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 64)   8192        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 64)   36864       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 256)  16384       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 256)  32768       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 256)  0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 64)   16384       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 64)   36864       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 256)  16384       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_18[0][0]                  \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   16384       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 64)   36864       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 256)  16384       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 256)  0           conv2d_21[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 256)  1024        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   16384       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 64)   36864       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 256)  16384       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 256)  0           conv2d_24[0][0]                  \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 256)  1024        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 256)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 128)  32768       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 128)    147456      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 512)    65536       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 512)    131072      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 512)    0           conv2d_27[0][0]                  \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 512)    2048        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 512)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 128)    65536       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 128)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147456      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 128)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 512)    65536       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 512)    0           conv2d_31[0][0]                  \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 512)    2048        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 512)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 128)    65536       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 128)    147456      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 512)    65536       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 512)    0           conv2d_34[0][0]                  \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 512)    2048        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 512)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 128)    65536       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 128)    147456      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 512)    65536       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 512)    0           conv2d_37[0][0]                  \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 512)    2048        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 512)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 128)    65536       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 128)    147456      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 512)    65536       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 512)    0           conv2d_40[0][0]                  \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 512)    2048        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 512)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 128)    65536       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 128)    512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 128)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 128)    147456      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 8, 8, 512)    65536       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 512)    0           conv2d_43[0][0]                  \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 512)    2048        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 8, 512)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 1, 1, 200)    102600      average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 200)          0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 200)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,265,748\n",
            "Trainable params: 2,252,046\n",
            "Non-trainable params: 13,702\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fq8ClAygFN-",
        "colab_type": "text"
      },
      "source": [
        "## Attempted to train 50 epochs but an error occurred after 35 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEVV7NQBHIxS",
        "colab_type": "code",
        "outputId": "34d46a0e-4a14-4557-c963-21390d70aa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1616
        }
      },
      "source": [
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 64,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 64,\n",
        "  epochs=50,\n",
        "  max_queue_size=64 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "\n",
        "# close the databases\n",
        "train_gen.close()\n",
        "val_gen.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1562/1562 [==============================] - 625s 400ms/step - loss: 5.2895 - acc: 0.0522 - val_loss: 4.9462 - val_acc: 0.0768\n",
            "Epoch 2/50\n",
            "1562/1562 [==============================] - 595s 381ms/step - loss: 4.5602 - acc: 0.1253 - val_loss: 5.1685 - val_acc: 0.1002\n",
            "Epoch 3/50\n",
            "1562/1562 [==============================] - 597s 382ms/step - loss: 4.2459 - acc: 0.1721 - val_loss: 4.4953 - val_acc: 0.1498\n",
            "Epoch 4/50\n",
            "1562/1562 [==============================] - 588s 376ms/step - loss: 4.0724 - acc: 0.2053 - val_loss: 4.4285 - val_acc: 0.1740\n",
            "Epoch 5/50\n",
            "1562/1562 [==============================] - 562s 360ms/step - loss: 3.9622 - acc: 0.2322 - val_loss: 4.6980 - val_acc: 0.1520\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/50\n",
            "1562/1562 [==============================] - 530s 339ms/step - loss: 3.8921 - acc: 0.2498 - val_loss: 4.1909 - val_acc: 0.2251\n",
            "Epoch 7/50\n",
            "1562/1562 [==============================] - 549s 351ms/step - loss: 3.8325 - acc: 0.2693 - val_loss: 4.3602 - val_acc: 0.2037\n",
            "Epoch 8/50\n",
            "1562/1562 [==============================] - 546s 349ms/step - loss: 3.7907 - acc: 0.2838 - val_loss: 4.2911 - val_acc: 0.2226\n",
            "Epoch 9/50\n",
            "1562/1562 [==============================] - 542s 347ms/step - loss: 3.7577 - acc: 0.2935 - val_loss: 4.4082 - val_acc: 0.2137\n",
            "Epoch 10/50\n",
            "1562/1562 [==============================] - 539s 345ms/step - loss: 3.7168 - acc: 0.3070 - val_loss: 4.8285 - val_acc: 0.1927\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/50\n",
            "1562/1562 [==============================] - 538s 345ms/step - loss: 3.6913 - acc: 0.3151 - val_loss: 4.2063 - val_acc: 0.2418\n",
            "Epoch 12/50\n",
            "1562/1562 [==============================] - 578s 370ms/step - loss: 3.6590 - acc: 0.3288 - val_loss: 4.4667 - val_acc: 0.2330\n",
            "Epoch 13/50\n",
            "1562/1562 [==============================] - 585s 375ms/step - loss: 3.6327 - acc: 0.3351 - val_loss: 4.3574 - val_acc: 0.2491\n",
            "Epoch 14/50\n",
            "1562/1562 [==============================] - 586s 375ms/step - loss: 3.6070 - acc: 0.3447 - val_loss: 4.1012 - val_acc: 0.2917\n",
            "Epoch 15/50\n",
            "1562/1562 [==============================] - 589s 377ms/step - loss: 3.5847 - acc: 0.3530 - val_loss: 3.9623 - val_acc: 0.3059\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/50\n",
            "1562/1562 [==============================] - 588s 377ms/step - loss: 3.5553 - acc: 0.3614 - val_loss: 4.0849 - val_acc: 0.3027\n",
            "Epoch 17/50\n",
            "1562/1562 [==============================] - 592s 379ms/step - loss: 3.5436 - acc: 0.3662 - val_loss: 3.8428 - val_acc: 0.3343\n",
            "Epoch 18/50\n",
            "1562/1562 [==============================] - 589s 377ms/step - loss: 3.5169 - acc: 0.3730 - val_loss: 3.9719 - val_acc: 0.3073\n",
            "Epoch 19/50\n",
            "1562/1562 [==============================] - 587s 376ms/step - loss: 3.5009 - acc: 0.3784 - val_loss: 4.0443 - val_acc: 0.3098\n",
            "Epoch 20/50\n",
            "1562/1562 [==============================] - 587s 376ms/step - loss: 3.4781 - acc: 0.3842 - val_loss: 3.7809 - val_acc: 0.3490\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/50\n",
            "1562/1562 [==============================] - 587s 376ms/step - loss: 3.4600 - acc: 0.3908 - val_loss: 3.9801 - val_acc: 0.3248\n",
            "Epoch 22/50\n",
            "1562/1562 [==============================] - 590s 378ms/step - loss: 3.4368 - acc: 0.3965 - val_loss: 3.8644 - val_acc: 0.3421\n",
            "Epoch 23/50\n",
            "1562/1562 [==============================] - 583s 373ms/step - loss: 3.4281 - acc: 0.3986 - val_loss: 4.0198 - val_acc: 0.3197\n",
            "Epoch 24/50\n",
            "1562/1562 [==============================] - 585s 375ms/step - loss: 3.4046 - acc: 0.4068 - val_loss: 4.1649 - val_acc: 0.3096\n",
            "Epoch 25/50\n",
            "1562/1562 [==============================] - 583s 373ms/step - loss: 3.3793 - acc: 0.4124 - val_loss: 4.1785 - val_acc: 0.3139\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/50\n",
            "1562/1562 [==============================] - 584s 374ms/step - loss: 3.3675 - acc: 0.4134 - val_loss: 3.4797 - val_acc: 0.3992\n",
            "Epoch 27/50\n",
            "1562/1562 [==============================] - 584s 374ms/step - loss: 3.3417 - acc: 0.4193 - val_loss: 3.6789 - val_acc: 0.3768\n",
            "Epoch 28/50\n",
            "1562/1562 [==============================] - 584s 374ms/step - loss: 3.3215 - acc: 0.4252 - val_loss: 3.7096 - val_acc: 0.3699\n",
            "Epoch 29/50\n",
            "1562/1562 [==============================] - 581s 372ms/step - loss: 3.3079 - acc: 0.4283 - val_loss: 3.8310 - val_acc: 0.3625\n",
            "Epoch 30/50\n",
            "1562/1562 [==============================] - 592s 379ms/step - loss: 3.2842 - acc: 0.4336 - val_loss: 3.9326 - val_acc: 0.3418\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/50\n",
            "1562/1562 [==============================] - 585s 374ms/step - loss: 3.2672 - acc: 0.4374 - val_loss: 3.7458 - val_acc: 0.3692\n",
            "Epoch 32/50\n",
            "1562/1562 [==============================] - 585s 375ms/step - loss: 3.2439 - acc: 0.4428 - val_loss: 3.6501 - val_acc: 0.3920\n",
            "Epoch 33/50\n",
            "1562/1562 [==============================] - 583s 373ms/step - loss: 3.2235 - acc: 0.4494 - val_loss: 3.8597 - val_acc: 0.3643\n",
            "Epoch 34/50\n",
            "1562/1562 [==============================] - 584s 374ms/step - loss: 3.2073 - acc: 0.4517 - val_loss: 3.8389 - val_acc: 0.3586\n",
            "Epoch 35/50\n",
            "1562/1562 [==============================] - 566s 363ms/step - loss: 3.1868 - acc: 0.4560 - val_loss: 3.6606 - val_acc: 0.3983\n",
            "\n",
            "Epoch 00035: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 36/50\n",
            "1562/1562 [==============================] - 544s 348ms/step - loss: 3.1673 - acc: 0.4602 - val_loss: 3.5344 - val_acc: 0.4098\n",
            "Epoch 37/50\n",
            "1562/1562 [==============================] - 540s 345ms/step - loss: 3.1426 - acc: 0.4629 - val_loss: 3.5655 - val_acc: 0.3981\n",
            "Epoch 38/50\n",
            "1163/1562 [=====================>........] - ETA: 2:13 - loss: 3.1036 - acc: 0.4742Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl0DcHLma-mu",
        "colab_type": "text"
      },
      "source": [
        "## There was a Buffered data error and thus had to stop the execution after 38 epochs and the model was saved after 35\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Total Epoch count: 35"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ojAwqJWa3Oo",
        "colab_type": "code",
        "outputId": "576de807-0096-47e7-c2fa-3cef52588fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1225
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD\n",
        "flag = 1\n",
        "\n",
        "if flag == 0: \n",
        "  model = ResNet.build(64, 64, 3, 200, (3, 4, 6), (64, 128, 256, 512), reg=0.0005)\n",
        "  opt = SGD(lr=INIT_LR, momentum=0.9)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#   model.compile(optimizer=Adam(0.1), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "else:\n",
        "  \n",
        "  # Load the model\n",
        "  model = load_model(checkpoint_path)\n",
        "  \n",
        "#   Update the learning rate\n",
        "  print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "  K.set_value(model.optimizer.lr, 0.1)\n",
        "  print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 64,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 64,\n",
        "  epochs=40,\n",
        "  max_queue_size=64 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old Learning Rate: 0.08666666597127914\n",
            "New Learning Rate: 0.10000000149011612\n",
            "Epoch 1/40\n",
            "1562/1562 [==============================] - 603s 386ms/step - loss: 3.6570 - acc: 0.3987 - val_loss: 4.1770 - val_acc: 0.3471\n",
            "Epoch 2/40\n",
            "1562/1562 [==============================] - 585s 374ms/step - loss: 3.6475 - acc: 0.4019 - val_loss: 3.9846 - val_acc: 0.3555\n",
            "Epoch 3/40\n",
            "1562/1562 [==============================] - 585s 375ms/step - loss: 3.6283 - acc: 0.4067 - val_loss: 4.0775 - val_acc: 0.3477\n",
            "Epoch 4/40\n",
            "1562/1562 [==============================] - 587s 376ms/step - loss: 3.6121 - acc: 0.4094 - val_loss: 4.1697 - val_acc: 0.3381\n",
            "Epoch 5/40\n",
            "1562/1562 [==============================] - 587s 376ms/step - loss: 3.5915 - acc: 0.4115 - val_loss: 4.0687 - val_acc: 0.3538\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/40\n",
            "1562/1562 [==============================] - 553s 354ms/step - loss: 3.5840 - acc: 0.4127 - val_loss: 3.8007 - val_acc: 0.3833\n",
            "Epoch 7/40\n",
            "1562/1562 [==============================] - 583s 373ms/step - loss: 3.5738 - acc: 0.4150 - val_loss: 3.8775 - val_acc: 0.3793\n",
            "Epoch 8/40\n",
            "1562/1562 [==============================] - 584s 374ms/step - loss: 3.5558 - acc: 0.4194 - val_loss: 4.1728 - val_acc: 0.3376\n",
            "Epoch 9/40\n",
            "1562/1562 [==============================] - 583s 373ms/step - loss: 3.5521 - acc: 0.4195 - val_loss: 4.1047 - val_acc: 0.3451\n",
            "Epoch 10/40\n",
            "1562/1562 [==============================] - 585s 375ms/step - loss: 3.5229 - acc: 0.4225 - val_loss: 3.8885 - val_acc: 0.3785\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/40\n",
            "1562/1562 [==============================] - 581s 372ms/step - loss: 3.5125 - acc: 0.4251 - val_loss: 4.4332 - val_acc: 0.3064\n",
            "Epoch 12/40\n",
            "1562/1562 [==============================] - 582s 372ms/step - loss: 3.5001 - acc: 0.4250 - val_loss: 3.9571 - val_acc: 0.3641\n",
            "Epoch 13/40\n",
            "1562/1562 [==============================] - 586s 375ms/step - loss: 3.4788 - acc: 0.4311 - val_loss: 3.9121 - val_acc: 0.3690\n",
            "Epoch 14/40\n",
            "1562/1562 [==============================] - 584s 374ms/step - loss: 3.4633 - acc: 0.4324 - val_loss: 4.2547 - val_acc: 0.3287\n",
            "Epoch 15/40\n",
            "1562/1562 [==============================] - 590s 378ms/step - loss: 3.4484 - acc: 0.4357 - val_loss: 3.9784 - val_acc: 0.3752\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/40\n",
            "1562/1562 [==============================] - 588s 376ms/step - loss: 3.4335 - acc: 0.4386 - val_loss: 3.8660 - val_acc: 0.3746\n",
            "Epoch 17/40\n",
            "1562/1562 [==============================] - 586s 375ms/step - loss: 3.4291 - acc: 0.4383 - val_loss: 3.8159 - val_acc: 0.3958\n",
            "Epoch 18/40\n",
            "1562/1562 [==============================] - 583s 373ms/step - loss: 3.4079 - acc: 0.4425 - val_loss: 3.7378 - val_acc: 0.4009\n",
            "Epoch 19/40\n",
            "1562/1562 [==============================] - 587s 376ms/step - loss: 3.3902 - acc: 0.4456 - val_loss: 3.6504 - val_acc: 0.4178\n",
            "Epoch 20/40\n",
            "1562/1562 [==============================] - 588s 377ms/step - loss: 3.3691 - acc: 0.4497 - val_loss: 4.0720 - val_acc: 0.3579\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/40\n",
            "1562/1562 [==============================] - 585s 375ms/step - loss: 3.3578 - acc: 0.4517 - val_loss: 3.7957 - val_acc: 0.3794\n",
            "Epoch 22/40\n",
            "1562/1562 [==============================] - 589s 377ms/step - loss: 3.3396 - acc: 0.4539 - val_loss: 4.1636 - val_acc: 0.3412\n",
            "Epoch 23/40\n",
            "1562/1562 [==============================] - 587s 376ms/step - loss: 3.3307 - acc: 0.4564 - val_loss: 3.6089 - val_acc: 0.4159\n",
            "Epoch 24/40\n",
            "1562/1562 [==============================] - 589s 377ms/step - loss: 3.3083 - acc: 0.4616 - val_loss: 3.7778 - val_acc: 0.3941\n",
            "Epoch 25/40\n",
            "1562/1562 [==============================] - 586s 375ms/step - loss: 3.2943 - acc: 0.4615 - val_loss: 3.8385 - val_acc: 0.3839\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/40\n",
            "1562/1562 [==============================] - 588s 377ms/step - loss: 3.2762 - acc: 0.4638 - val_loss: 3.6250 - val_acc: 0.4106\n",
            "Epoch 27/40\n",
            "1562/1562 [==============================] - 586s 375ms/step - loss: 3.2612 - acc: 0.4686 - val_loss: 3.9866 - val_acc: 0.3542\n",
            "Epoch 28/40\n",
            "1090/1562 [===================>..........] - ETA: 2:53 - loss: 3.2316 - acc: 0.4710"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgJPIjEeBBfy",
        "colab_type": "text"
      },
      "source": [
        "## Colab disconnected after 28 epochs and was saved at 25 epochs\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Total epochs = 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEp3qUzYQ3x4",
        "colab_type": "code",
        "outputId": "171574d7-47b0-4f1d-af4e-8003c6f208c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1403
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD\n",
        "flag = 1\n",
        "\n",
        "if flag == 0: \n",
        "  model = ResNet.build(64, 64, 3, 200, (3, 4, 6), (64, 128, 256, 512), reg=0.0005)\n",
        "  opt = SGD(lr=INIT_LR, momentum=0.9)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#   model.compile(optimizer=Adam(0.1), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "else:\n",
        "  \n",
        "  # Load the model\n",
        "  model = load_model(checkpoint_path)\n",
        "  \n",
        "#   Update the learning rate\n",
        "  print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "  K.set_value(model.optimizer.lr, 0.005)\n",
        "  print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 64,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 64,\n",
        "  epochs=35,\n",
        "  max_queue_size=64 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old Learning Rate: 0.04800000041723251\n",
            "New Learning Rate: 0.004999999888241291\n",
            "Epoch 1/35\n",
            "1562/1562 [==============================] - 565s 362ms/step - loss: 3.6756 - acc: 0.4125 - val_loss: 3.9539 - val_acc: 0.3959\n",
            "Epoch 2/35\n",
            "1562/1562 [==============================] - 553s 354ms/step - loss: 3.6580 - acc: 0.4309 - val_loss: 3.7107 - val_acc: 0.4328\n",
            "Epoch 3/35\n",
            "1562/1562 [==============================] - 552s 354ms/step - loss: 3.6197 - acc: 0.4363 - val_loss: 3.8290 - val_acc: 0.4160\n",
            "Epoch 4/35\n",
            "1562/1562 [==============================] - 553s 354ms/step - loss: 3.6019 - acc: 0.4382 - val_loss: 3.8936 - val_acc: 0.3996\n",
            "Epoch 5/35\n",
            "1562/1562 [==============================] - 555s 355ms/step - loss: 3.5804 - acc: 0.4405 - val_loss: 5.0070 - val_acc: 0.2900\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "1562/1562 [==============================] - 522s 334ms/step - loss: 3.5633 - acc: 0.4413 - val_loss: 4.3363 - val_acc: 0.3408\n",
            "Epoch 7/35\n",
            "1562/1562 [==============================] - 551s 353ms/step - loss: 3.5545 - acc: 0.4417 - val_loss: 4.2473 - val_acc: 0.3514\n",
            "Epoch 8/35\n",
            "1562/1562 [==============================] - 550s 352ms/step - loss: 3.5290 - acc: 0.4456 - val_loss: 4.0823 - val_acc: 0.3771\n",
            "Epoch 9/35\n",
            "1562/1562 [==============================] - 544s 348ms/step - loss: 3.5220 - acc: 0.4447 - val_loss: 4.0439 - val_acc: 0.3747\n",
            "Epoch 10/35\n",
            "1562/1562 [==============================] - 544s 348ms/step - loss: 3.5046 - acc: 0.4481 - val_loss: 3.7995 - val_acc: 0.4127\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.4781 - acc: 0.4508 - val_loss: 3.7478 - val_acc: 0.4143\n",
            "Epoch 12/35\n",
            "1562/1562 [==============================] - 552s 354ms/step - loss: 3.4737 - acc: 0.4513 - val_loss: 3.7395 - val_acc: 0.4188\n",
            "Epoch 13/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.4650 - acc: 0.4519 - val_loss: 3.7658 - val_acc: 0.4135\n",
            "Epoch 14/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.4389 - acc: 0.4551 - val_loss: 4.0095 - val_acc: 0.3761\n",
            "Epoch 15/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.4289 - acc: 0.4574 - val_loss: 3.9328 - val_acc: 0.3845\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/35\n",
            "1562/1562 [==============================] - 545s 349ms/step - loss: 3.4053 - acc: 0.4606 - val_loss: 3.7822 - val_acc: 0.4150\n",
            "Epoch 17/35\n",
            "1562/1562 [==============================] - 545s 349ms/step - loss: 3.3949 - acc: 0.4646 - val_loss: 3.8391 - val_acc: 0.4105\n",
            "Epoch 18/35\n",
            "1562/1562 [==============================] - 544s 348ms/step - loss: 3.3774 - acc: 0.4654 - val_loss: 3.8293 - val_acc: 0.4054\n",
            "Epoch 19/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.3586 - acc: 0.4659 - val_loss: 3.8630 - val_acc: 0.4048\n",
            "Epoch 20/35\n",
            "1562/1562 [==============================] - 547s 350ms/step - loss: 3.3507 - acc: 0.4680 - val_loss: 3.6296 - val_acc: 0.4389\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.3320 - acc: 0.4700 - val_loss: 3.7412 - val_acc: 0.4202\n",
            "Epoch 22/35\n",
            "1562/1562 [==============================] - 547s 350ms/step - loss: 3.3047 - acc: 0.4749 - val_loss: 3.5420 - val_acc: 0.4484\n",
            "Epoch 23/35\n",
            "1562/1562 [==============================] - 545s 349ms/step - loss: 3.2956 - acc: 0.4772 - val_loss: 3.7386 - val_acc: 0.4185\n",
            "Epoch 24/35\n",
            "1562/1562 [==============================] - 552s 353ms/step - loss: 3.2725 - acc: 0.4797 - val_loss: 3.6004 - val_acc: 0.4346\n",
            "Epoch 25/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.2587 - acc: 0.4820 - val_loss: 3.5713 - val_acc: 0.4432\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.2326 - acc: 0.4867 - val_loss: 3.6716 - val_acc: 0.4241\n",
            "Epoch 27/35\n",
            "1562/1562 [==============================] - 549s 351ms/step - loss: 3.2370 - acc: 0.4852 - val_loss: 3.9047 - val_acc: 0.3937\n",
            "Epoch 28/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.2059 - acc: 0.4908 - val_loss: 3.7569 - val_acc: 0.4146\n",
            "Epoch 29/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.1862 - acc: 0.4928 - val_loss: 4.0251 - val_acc: 0.3715\n",
            "Epoch 30/35\n",
            "1562/1562 [==============================] - 548s 351ms/step - loss: 3.1722 - acc: 0.4942 - val_loss: 3.7154 - val_acc: 0.4176\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/35\n",
            "1562/1562 [==============================] - 549s 351ms/step - loss: 3.1459 - acc: 0.5005 - val_loss: 3.6949 - val_acc: 0.4198\n",
            "Epoch 32/35\n",
            " 234/1562 [===>..........................] - ETA: 7:21 - loss: 3.1492 - acc: 0.4955"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqsTQjZot9gi",
        "colab_type": "text"
      },
      "source": [
        "## Another 30 epochs where model was saved\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Total epochs = 90"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyDw5cZkuHno",
        "colab_type": "code",
        "outputId": "f59f2b8e-e5ad-422a-cde3-a195e71c4541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1636
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD\n",
        "flag = 1\n",
        "\n",
        "if flag == 0: \n",
        "  model = ResNet.build(64, 64, 3, 200, (3, 4, 6), (64, 128, 256, 512), reg=0.0005)\n",
        "  opt = SGD(lr=INIT_LR, momentum=0.9)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "else:\n",
        "  \n",
        "  # Load the model\n",
        "  model = load_model(checkpoint_path)\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 64,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 64,\n",
        "  epochs=35,\n",
        "  max_queue_size=64 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/35\n",
            "1562/1562 [==============================] - 580s 371ms/step - loss: 3.6153 - acc: 0.4358 - val_loss: 4.1227 - val_acc: 0.3787\n",
            "Epoch 2/35\n",
            "1562/1562 [==============================] - 557s 356ms/step - loss: 3.6074 - acc: 0.4396 - val_loss: 4.2174 - val_acc: 0.3608\n",
            "Epoch 3/35\n",
            "1562/1562 [==============================] - 552s 354ms/step - loss: 3.5930 - acc: 0.4424 - val_loss: 4.2454 - val_acc: 0.3555\n",
            "Epoch 4/35\n",
            "1562/1562 [==============================] - 544s 348ms/step - loss: 3.5772 - acc: 0.4428 - val_loss: 3.7043 - val_acc: 0.4287\n",
            "Epoch 5/35\n",
            "1562/1562 [==============================] - 535s 343ms/step - loss: 3.5520 - acc: 0.4472 - val_loss: 4.2623 - val_acc: 0.3523\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "1562/1562 [==============================] - 518s 332ms/step - loss: 3.5438 - acc: 0.4466 - val_loss: 3.9182 - val_acc: 0.4058\n",
            "Epoch 7/35\n",
            "1562/1562 [==============================] - 529s 339ms/step - loss: 3.5345 - acc: 0.4482 - val_loss: 4.0362 - val_acc: 0.3750\n",
            "Epoch 8/35\n",
            "1562/1562 [==============================] - 528s 338ms/step - loss: 3.5218 - acc: 0.4477 - val_loss: 3.8565 - val_acc: 0.4115\n",
            "Epoch 9/35\n",
            "1562/1562 [==============================] - 526s 336ms/step - loss: 3.5014 - acc: 0.4520 - val_loss: 4.1343 - val_acc: 0.3621\n",
            "Epoch 10/35\n",
            "1562/1562 [==============================] - 525s 336ms/step - loss: 3.4886 - acc: 0.4547 - val_loss: 3.9515 - val_acc: 0.3893\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/35\n",
            "1562/1562 [==============================] - 517s 331ms/step - loss: 3.4656 - acc: 0.4579 - val_loss: 3.7258 - val_acc: 0.4173\n",
            "Epoch 12/35\n",
            "1562/1562 [==============================] - 518s 332ms/step - loss: 3.4582 - acc: 0.4574 - val_loss: 3.7496 - val_acc: 0.4242\n",
            "Epoch 13/35\n",
            "1562/1562 [==============================] - 520s 333ms/step - loss: 3.4437 - acc: 0.4596 - val_loss: 4.2877 - val_acc: 0.3520\n",
            "Epoch 14/35\n",
            "1562/1562 [==============================] - 511s 327ms/step - loss: 3.4215 - acc: 0.4651 - val_loss: 4.1579 - val_acc: 0.3623\n",
            "Epoch 15/35\n",
            "1562/1562 [==============================] - 520s 333ms/step - loss: 3.4109 - acc: 0.4628 - val_loss: 3.8314 - val_acc: 0.4015\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/35\n",
            "1562/1562 [==============================] - 531s 340ms/step - loss: 3.3894 - acc: 0.4676 - val_loss: 3.8572 - val_acc: 0.4061\n",
            "Epoch 17/35\n",
            "1562/1562 [==============================] - 539s 345ms/step - loss: 3.3772 - acc: 0.4701 - val_loss: 4.2562 - val_acc: 0.3671\n",
            "Epoch 18/35\n",
            "1562/1562 [==============================] - 520s 333ms/step - loss: 3.3609 - acc: 0.4724 - val_loss: 3.7874 - val_acc: 0.4111\n",
            "Epoch 19/35\n",
            "1562/1562 [==============================] - 514s 329ms/step - loss: 3.3468 - acc: 0.4744 - val_loss: 3.8137 - val_acc: 0.4116\n",
            "Epoch 20/35\n",
            "1562/1562 [==============================] - 513s 328ms/step - loss: 3.3298 - acc: 0.4762 - val_loss: 3.6948 - val_acc: 0.4336\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/35\n",
            "1562/1562 [==============================] - 519s 333ms/step - loss: 3.3223 - acc: 0.4775 - val_loss: 3.8535 - val_acc: 0.4077\n",
            "Epoch 22/35\n",
            "1562/1562 [==============================] - 524s 335ms/step - loss: 3.2884 - acc: 0.4809 - val_loss: 3.8693 - val_acc: 0.3948\n",
            "Epoch 23/35\n",
            "1562/1562 [==============================] - 530s 339ms/step - loss: 3.2743 - acc: 0.4852 - val_loss: 3.6098 - val_acc: 0.4312\n",
            "Epoch 24/35\n",
            "1562/1562 [==============================] - 527s 337ms/step - loss: 3.2668 - acc: 0.4839 - val_loss: 4.1668 - val_acc: 0.3624\n",
            "Epoch 25/35\n",
            "1562/1562 [==============================] - 522s 334ms/step - loss: 3.2353 - acc: 0.4905 - val_loss: 3.4898 - val_acc: 0.4560\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/35\n",
            "1562/1562 [==============================] - 526s 337ms/step - loss: 3.2220 - acc: 0.4910 - val_loss: 3.5258 - val_acc: 0.4529\n",
            "Epoch 27/35\n",
            "1562/1562 [==============================] - 529s 339ms/step - loss: 3.2094 - acc: 0.4934 - val_loss: 3.6449 - val_acc: 0.4287\n",
            "Epoch 28/35\n",
            "1562/1562 [==============================] - 529s 339ms/step - loss: 3.1930 - acc: 0.4958 - val_loss: 3.9095 - val_acc: 0.4105\n",
            "Epoch 29/35\n",
            "1562/1562 [==============================] - 542s 347ms/step - loss: 3.1751 - acc: 0.4978 - val_loss: 3.8113 - val_acc: 0.4206\n",
            "Epoch 30/35\n",
            "1562/1562 [==============================] - 542s 347ms/step - loss: 3.1554 - acc: 0.5013 - val_loss: 3.6129 - val_acc: 0.4400\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/35\n",
            "1562/1562 [==============================] - 547s 350ms/step - loss: 3.1249 - acc: 0.5062 - val_loss: 3.6479 - val_acc: 0.4322\n",
            "Epoch 32/35\n",
            "1562/1562 [==============================] - 547s 350ms/step - loss: 3.1185 - acc: 0.5077 - val_loss: 3.4707 - val_acc: 0.4548\n",
            "Epoch 33/35\n",
            "1562/1562 [==============================] - 564s 361ms/step - loss: 3.1040 - acc: 0.5091 - val_loss: 3.7815 - val_acc: 0.4147\n",
            "Epoch 34/35\n",
            "1562/1562 [==============================] - 573s 367ms/step - loss: 3.0662 - acc: 0.5137 - val_loss: 3.8946 - val_acc: 0.4021\n",
            "Epoch 35/35\n",
            "1562/1562 [==============================] - 554s 355ms/step - loss: 3.0508 - acc: 0.5186 - val_loss: 3.5256 - val_acc: 0.4521\n",
            "\n",
            "Epoch 00035: saving model to ../checkpoints/check.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVjFyNyoCbHW",
        "colab_type": "text"
      },
      "source": [
        "## Trained for another 35 epochs and noticed the variability of the data. Therefore decided to further reduce the learning rate and stop Cyclic Learning Rate and replace with Learning Rate Decay\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "##  Total Epochs = 125"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwh9LbrvuP2R",
        "colab_type": "code",
        "outputId": "802960e2-0cc0-48fc-9690-212ee524751e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1527
        }
      },
      "source": [
        "K.set_value(model.optimizer.momentum, 0.9)\n",
        "print(K.get_value(model.optimizer.momentum))\n",
        "\n",
        "model = load_model(checkpoint_path)\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 64,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 64,\n",
        "  epochs=35,\n",
        "  max_queue_size=64 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9\n",
            "Epoch 1/35\n",
            "1562/1562 [==============================] - 563s 360ms/step - loss: 3.6252 - acc: 0.4309 - val_loss: 4.4610 - val_acc: 0.3353\n",
            "Epoch 2/35\n",
            "1562/1562 [==============================] - 561s 359ms/step - loss: 3.6410 - acc: 0.4422 - val_loss: 4.3583 - val_acc: 0.3448\n",
            "Epoch 3/35\n",
            "1562/1562 [==============================] - 568s 364ms/step - loss: 3.6180 - acc: 0.4436 - val_loss: 4.2812 - val_acc: 0.3707\n",
            "Epoch 4/35\n",
            "1562/1562 [==============================] - 563s 361ms/step - loss: 3.5863 - acc: 0.4489 - val_loss: 3.9269 - val_acc: 0.4130\n",
            "Epoch 5/35\n",
            "1562/1562 [==============================] - 569s 364ms/step - loss: 3.5695 - acc: 0.4510 - val_loss: 4.1916 - val_acc: 0.3697\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "1562/1562 [==============================] - 539s 345ms/step - loss: 3.5513 - acc: 0.4513 - val_loss: 4.4334 - val_acc: 0.3386\n",
            "Epoch 7/35\n",
            "1562/1562 [==============================] - 568s 364ms/step - loss: 3.5440 - acc: 0.4524 - val_loss: 3.9984 - val_acc: 0.3949\n",
            "Epoch 8/35\n",
            "1562/1562 [==============================] - 569s 364ms/step - loss: 3.5214 - acc: 0.4541 - val_loss: 4.0846 - val_acc: 0.3737\n",
            "Epoch 9/35\n",
            "1562/1562 [==============================] - 568s 364ms/step - loss: 3.5016 - acc: 0.4567 - val_loss: 3.7784 - val_acc: 0.4197\n",
            "Epoch 10/35\n",
            "1562/1562 [==============================] - 567s 363ms/step - loss: 3.4864 - acc: 0.4576 - val_loss: 4.0161 - val_acc: 0.4030\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/35\n",
            "1562/1562 [==============================] - 551s 353ms/step - loss: 3.4693 - acc: 0.4612 - val_loss: 4.1743 - val_acc: 0.3725\n",
            "Epoch 12/35\n",
            "1562/1562 [==============================] - 569s 364ms/step - loss: 3.4606 - acc: 0.4620 - val_loss: 3.8022 - val_acc: 0.4149\n",
            "Epoch 13/35\n",
            "1562/1562 [==============================] - 558s 357ms/step - loss: 3.4517 - acc: 0.4638 - val_loss: 4.0491 - val_acc: 0.3839\n",
            "Epoch 14/35\n",
            "1562/1562 [==============================] - 554s 355ms/step - loss: 3.4291 - acc: 0.4653 - val_loss: 4.0850 - val_acc: 0.3787\n",
            "Epoch 15/35\n",
            "1562/1562 [==============================] - 549s 351ms/step - loss: 3.4130 - acc: 0.4682 - val_loss: 3.9448 - val_acc: 0.3865\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/35\n",
            "1562/1562 [==============================] - 547s 350ms/step - loss: 3.3950 - acc: 0.4696 - val_loss: 3.7671 - val_acc: 0.4246\n",
            "Epoch 17/35\n",
            "1562/1562 [==============================] - 549s 351ms/step - loss: 3.3805 - acc: 0.4728 - val_loss: 3.9817 - val_acc: 0.3972\n",
            "Epoch 18/35\n",
            "1562/1562 [==============================] - 550s 352ms/step - loss: 3.3528 - acc: 0.4756 - val_loss: 4.0666 - val_acc: 0.3884\n",
            "Epoch 19/35\n",
            "1562/1562 [==============================] - 553s 354ms/step - loss: 3.3626 - acc: 0.4744 - val_loss: 3.8184 - val_acc: 0.4280\n",
            "Epoch 20/35\n",
            "1562/1562 [==============================] - 555s 355ms/step - loss: 3.3296 - acc: 0.4784 - val_loss: 4.1964 - val_acc: 0.3713\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/35\n",
            "1562/1562 [==============================] - 557s 357ms/step - loss: 3.3198 - acc: 0.4781 - val_loss: 3.6414 - val_acc: 0.4419\n",
            "Epoch 22/35\n",
            "1562/1562 [==============================] - 559s 358ms/step - loss: 3.2922 - acc: 0.4844 - val_loss: 3.7571 - val_acc: 0.4207\n",
            "Epoch 23/35\n",
            "1562/1562 [==============================] - 552s 353ms/step - loss: 3.2802 - acc: 0.4863 - val_loss: 3.5891 - val_acc: 0.4479\n",
            "Epoch 24/35\n",
            "1562/1562 [==============================] - 564s 361ms/step - loss: 3.2561 - acc: 0.4889 - val_loss: 3.5196 - val_acc: 0.4579\n",
            "Epoch 25/35\n",
            "1562/1562 [==============================] - 562s 360ms/step - loss: 3.2395 - acc: 0.4916 - val_loss: 3.6250 - val_acc: 0.4433\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/35\n",
            "1562/1562 [==============================] - 563s 361ms/step - loss: 3.2286 - acc: 0.4949 - val_loss: 3.9737 - val_acc: 0.3937\n",
            "Epoch 27/35\n",
            "1562/1562 [==============================] - 565s 362ms/step - loss: 3.2116 - acc: 0.4955 - val_loss: 4.0128 - val_acc: 0.4052\n",
            "Epoch 28/35\n",
            "1562/1562 [==============================] - 565s 362ms/step - loss: 3.1942 - acc: 0.4979 - val_loss: 3.5353 - val_acc: 0.4533\n",
            "Epoch 29/35\n",
            "1562/1562 [==============================] - 566s 362ms/step - loss: 3.1769 - acc: 0.5003 - val_loss: 3.6905 - val_acc: 0.4300\n",
            "Epoch 30/35\n",
            "1562/1562 [==============================] - 561s 359ms/step - loss: 3.1473 - acc: 0.5055 - val_loss: 3.6657 - val_acc: 0.4367\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/35\n",
            "1562/1562 [==============================] - 564s 361ms/step - loss: 3.1309 - acc: 0.5070 - val_loss: 4.1061 - val_acc: 0.3801\n",
            "Epoch 32/35\n",
            "1562/1562 [==============================] - 555s 356ms/step - loss: 3.1114 - acc: 0.5097 - val_loss: 3.5199 - val_acc: 0.4536\n",
            "Epoch 33/35\n",
            "1562/1562 [==============================] - 554s 355ms/step - loss: 3.0890 - acc: 0.5118 - val_loss: 3.4560 - val_acc: 0.4603\n",
            "Epoch 34/35\n",
            "1562/1562 [==============================] - 554s 355ms/step - loss: 3.0717 - acc: 0.5159 - val_loss: 3.6242 - val_acc: 0.4380\n",
            "Epoch 35/35\n",
            "1562/1562 [==============================] - 545s 349ms/step - loss: 3.0445 - acc: 0.5200 - val_loss: 3.4909 - val_acc: 0.4548\n",
            "\n",
            "Epoch 00035: saving model to ../checkpoints/check.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT4UdN4CVk0g",
        "colab_type": "text"
      },
      "source": [
        "## The model training has been very slow. Thus, I've increased the batch size and changed to CLR from Learning Rate Decay\n",
        "\n",
        "---\n",
        "\n",
        "## Total Epochs = 160"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrVPxOULK15w",
        "colab_type": "code",
        "outputId": "107f48c2-44e1-409e-efdf-7158a832679f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 128,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 128,\n",
        "  epochs=35,\n",
        "  max_queue_size=128 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "  2/781 [..............................] - ETA: 1:24:55 - loss: 2.9759 - acc: 0.5352"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.572852). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "781/781 [==============================] - 415s 531ms/step - loss: 2.5838 - acc: 0.6194 - val_loss: 3.0819 - val_acc: 0.5332\n",
            "Epoch 2/35\n",
            "781/781 [==============================] - 384s 491ms/step - loss: 2.5295 - acc: 0.6106 - val_loss: 3.5392 - val_acc: 0.4467\n",
            "Epoch 3/35\n",
            "781/781 [==============================] - 383s 491ms/step - loss: 2.8241 - acc: 0.5469 - val_loss: 3.5283 - val_acc: 0.4502\n",
            "Epoch 4/35\n",
            "781/781 [==============================] - 385s 493ms/step - loss: 2.6342 - acc: 0.5870 - val_loss: 3.1412 - val_acc: 0.5056\n",
            "Epoch 5/35\n",
            "781/781 [==============================] - 386s 494ms/step - loss: 2.2284 - acc: 0.6655 - val_loss: 2.8317 - val_acc: 0.5506\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "781/781 [==============================] - 370s 474ms/step - loss: 2.0306 - acc: 0.7058 - val_loss: 3.0236 - val_acc: 0.5145\n",
            "Epoch 7/35\n",
            "781/781 [==============================] - 370s 474ms/step - loss: 2.3653 - acc: 0.6195 - val_loss: 3.3761 - val_acc: 0.4444\n",
            "Epoch 8/35\n",
            "781/781 [==============================] - 372s 476ms/step - loss: 2.8157 - acc: 0.5355 - val_loss: 3.2665 - val_acc: 0.4766\n",
            "Epoch 9/35\n",
            "781/781 [==============================] - 370s 474ms/step - loss: 2.6719 - acc: 0.5775 - val_loss: 3.1037 - val_acc: 0.5169\n",
            "Epoch 10/35\n",
            "140/781 [====>.........................] - ETA: 4:52 - loss: 2.3453 - acc: 0.6445"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvfRR0IpmaSp",
        "colab_type": "text"
      },
      "source": [
        "## Only 5 epochs were saved! \n",
        "\n",
        "---\n",
        "\n",
        "## Total Epochs = 165"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz9PRrwtmYw5",
        "colab_type": "code",
        "outputId": "3c927708-b8a8-4957-b8c9-ee0fd08ab17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1510
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 128,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 128,\n",
        "  epochs=35,\n",
        "  max_queue_size=128 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "781/781 [==============================] - 430s 550ms/step - loss: 2.0517 - acc: 0.7000 - val_loss: 2.9504 - val_acc: 0.5201\n",
            "Epoch 2/35\n",
            "781/781 [==============================] - 402s 515ms/step - loss: 2.4252 - acc: 0.6073 - val_loss: 3.5299 - val_acc: 0.4311\n",
            "Epoch 3/35\n",
            "781/781 [==============================] - 410s 525ms/step - loss: 2.8444 - acc: 0.5341 - val_loss: 3.4779 - val_acc: 0.4537\n",
            "Epoch 4/35\n",
            "781/781 [==============================] - 410s 525ms/step - loss: 2.6202 - acc: 0.5883 - val_loss: 3.3111 - val_acc: 0.4709\n",
            "Epoch 5/35\n",
            "781/781 [==============================] - 411s 526ms/step - loss: 2.1995 - acc: 0.6718 - val_loss: 2.8467 - val_acc: 0.5510\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "781/781 [==============================] - 376s 481ms/step - loss: 2.0025 - acc: 0.7122 - val_loss: 3.1268 - val_acc: 0.4958\n",
            "Epoch 7/35\n",
            "781/781 [==============================] - 407s 522ms/step - loss: 2.3647 - acc: 0.6219 - val_loss: 3.1118 - val_acc: 0.4932\n",
            "Epoch 8/35\n",
            "781/781 [==============================] - 411s 527ms/step - loss: 2.8292 - acc: 0.5357 - val_loss: 3.3155 - val_acc: 0.4710\n",
            "Epoch 9/35\n",
            "781/781 [==============================] - 409s 524ms/step - loss: 2.6798 - acc: 0.5771 - val_loss: 3.5190 - val_acc: 0.4543\n",
            "Epoch 10/35\n",
            "781/781 [==============================] - 410s 525ms/step - loss: 2.2582 - acc: 0.6630 - val_loss: 2.8132 - val_acc: 0.5592\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/35\n",
            "781/781 [==============================] - 400s 512ms/step - loss: 1.9783 - acc: 0.7219 - val_loss: 3.0319 - val_acc: 0.5200\n",
            "Epoch 12/35\n",
            "781/781 [==============================] - 398s 509ms/step - loss: 2.3052 - acc: 0.6348 - val_loss: 3.7232 - val_acc: 0.4025\n",
            "Epoch 13/35\n",
            "781/781 [==============================] - 398s 510ms/step - loss: 2.7988 - acc: 0.5434 - val_loss: 3.5800 - val_acc: 0.4279\n",
            "Epoch 14/35\n",
            "781/781 [==============================] - 396s 507ms/step - loss: 2.7340 - acc: 0.5710 - val_loss: 3.0630 - val_acc: 0.5168\n",
            "Epoch 15/35\n",
            "781/781 [==============================] - 405s 518ms/step - loss: 2.3006 - acc: 0.6551 - val_loss: 2.8683 - val_acc: 0.5562\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/35\n",
            "781/781 [==============================] - 402s 514ms/step - loss: 1.9800 - acc: 0.7254 - val_loss: 2.9212 - val_acc: 0.5466\n",
            "Epoch 17/35\n",
            "781/781 [==============================] - 396s 507ms/step - loss: 2.2380 - acc: 0.6545 - val_loss: 3.4224 - val_acc: 0.4480\n",
            "Epoch 18/35\n",
            "781/781 [==============================] - 398s 509ms/step - loss: 2.7579 - acc: 0.5500 - val_loss: 3.4746 - val_acc: 0.4509\n",
            "Epoch 19/35\n",
            "781/781 [==============================] - 392s 502ms/step - loss: 2.7885 - acc: 0.5605 - val_loss: 3.4293 - val_acc: 0.4578\n",
            "Epoch 20/35\n",
            "781/781 [==============================] - 395s 506ms/step - loss: 2.3652 - acc: 0.6468 - val_loss: 2.9453 - val_acc: 0.5354\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/35\n",
            "781/781 [==============================] - 395s 505ms/step - loss: 1.9982 - acc: 0.7247 - val_loss: 2.9542 - val_acc: 0.5477\n",
            "Epoch 22/35\n",
            "781/781 [==============================] - 402s 515ms/step - loss: 2.1916 - acc: 0.6678 - val_loss: 3.1507 - val_acc: 0.4949\n",
            "Epoch 23/35\n",
            "781/781 [==============================] - 400s 513ms/step - loss: 2.7054 - acc: 0.5622 - val_loss: 4.1635 - val_acc: 0.3502\n",
            "Epoch 24/35\n",
            "781/781 [==============================] - 398s 510ms/step - loss: 2.8417 - acc: 0.5514 - val_loss: 3.2168 - val_acc: 0.5027\n",
            "Epoch 25/35\n",
            "781/781 [==============================] - 396s 507ms/step - loss: 2.4157 - acc: 0.6380 - val_loss: 2.9189 - val_acc: 0.5548\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/35\n",
            "781/781 [==============================] - 403s 515ms/step - loss: 2.0156 - acc: 0.7231 - val_loss: 2.8520 - val_acc: 0.5651\n",
            "Epoch 27/35\n",
            "781/781 [==============================] - 405s 519ms/step - loss: 2.1415 - acc: 0.6832 - val_loss: 3.1806 - val_acc: 0.4911\n",
            "Epoch 28/35\n",
            "781/781 [==============================] - 407s 521ms/step - loss: 2.6514 - acc: 0.5716 - val_loss: 3.7123 - val_acc: 0.4222\n",
            "Epoch 29/35\n",
            "781/781 [==============================] - 405s 519ms/step - loss: 2.8763 - acc: 0.5453 - val_loss: 3.8366 - val_acc: 0.4145\n",
            "Epoch 30/35\n",
            "781/781 [==============================] - 397s 508ms/step - loss: 2.4666 - acc: 0.6286 - val_loss: 3.0488 - val_acc: 0.5246\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/35\n",
            "781/781 [==============================] - 398s 510ms/step - loss: 2.0541 - acc: 0.7180 - val_loss: 2.8899 - val_acc: 0.5601\n",
            "Epoch 32/35\n",
            "781/781 [==============================] - 398s 510ms/step - loss: 2.0887 - acc: 0.6982 - val_loss: 3.1863 - val_acc: 0.4976\n",
            "Epoch 33/35\n",
            "781/781 [==============================] - 397s 508ms/step - loss: 2.5887 - acc: 0.5864 - val_loss: 3.8141 - val_acc: 0.4040\n",
            "Epoch 34/35\n",
            "781/781 [==============================] - 398s 509ms/step - loss: 2.9070 - acc: 0.5378 - val_loss: 3.6203 - val_acc: 0.4442\n",
            "Epoch 35/35\n",
            "781/781 [==============================] - 405s 519ms/step - loss: 2.5331 - acc: 0.6184 - val_loss: 2.9737 - val_acc: 0.5422\n",
            "\n",
            "Epoch 00035: saving model to ../checkpoints/check.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD5GFcVc7inC",
        "colab_type": "text"
      },
      "source": [
        "## Total Epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY2s3uolmnLJ",
        "colab_type": "code",
        "outputId": "33f2792c-e41c-48a0-98f0-9eab7e332569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1583
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 256,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 256,\n",
        "  epochs=35,\n",
        "  max_queue_size=128 * 4,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/35\n",
            "390/390 [==============================] - 394s 1s/step - loss: 2.2497 - acc: 0.6872 - val_loss: 3.0517 - val_acc: 0.5413\n",
            "Epoch 2/35\n",
            "390/390 [==============================] - 325s 833ms/step - loss: 2.0525 - acc: 0.7284 - val_loss: 3.0347 - val_acc: 0.5453\n",
            "Epoch 3/35\n",
            "390/390 [==============================] - 326s 835ms/step - loss: 2.0216 - acc: 0.7221 - val_loss: 2.9802 - val_acc: 0.5394\n",
            "Epoch 4/35\n",
            "390/390 [==============================] - 326s 836ms/step - loss: 2.0745 - acc: 0.6966 - val_loss: 3.1678 - val_acc: 0.5073\n",
            "Epoch 5/35\n",
            "390/390 [==============================] - 326s 836ms/step - loss: 2.2135 - acc: 0.6592 - val_loss: 3.3584 - val_acc: 0.4680\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "390/390 [==============================] - 314s 805ms/step - loss: 2.2881 - acc: 0.6443 - val_loss: 3.0881 - val_acc: 0.5142\n",
            "Epoch 7/35\n",
            "390/390 [==============================] - 318s 816ms/step - loss: 2.1359 - acc: 0.6771 - val_loss: 2.9648 - val_acc: 0.5359\n",
            "Epoch 8/35\n",
            "390/390 [==============================] - 326s 836ms/step - loss: 1.9617 - acc: 0.7119 - val_loss: 3.3383 - val_acc: 0.4857\n",
            "Epoch 9/35\n",
            "390/390 [==============================] - 323s 829ms/step - loss: 1.7711 - acc: 0.7541 - val_loss: 3.1226 - val_acc: 0.5155\n",
            "Epoch 10/35\n",
            "390/390 [==============================] - 327s 838ms/step - loss: 1.5971 - acc: 0.7953 - val_loss: 2.8367 - val_acc: 0.5609\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/35\n",
            "390/390 [==============================] - 323s 829ms/step - loss: 1.4953 - acc: 0.8194 - val_loss: 2.8139 - val_acc: 0.5614\n",
            "Epoch 12/35\n",
            "390/390 [==============================] - 322s 826ms/step - loss: 1.5567 - acc: 0.7965 - val_loss: 2.8459 - val_acc: 0.5600\n",
            "Epoch 13/35\n",
            "390/390 [==============================] - 318s 816ms/step - loss: 1.7165 - acc: 0.7491 - val_loss: 2.9819 - val_acc: 0.5185\n",
            "Epoch 14/35\n",
            "390/390 [==============================] - 319s 818ms/step - loss: 1.9462 - acc: 0.6907 - val_loss: 3.0696 - val_acc: 0.4978\n",
            "Epoch 15/35\n",
            "390/390 [==============================] - 318s 816ms/step - loss: 2.1708 - acc: 0.6460 - val_loss: 3.2187 - val_acc: 0.4859\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/35\n",
            "390/390 [==============================] - 319s 818ms/step - loss: 2.3265 - acc: 0.6249 - val_loss: 3.3628 - val_acc: 0.4725\n",
            "Epoch 17/35\n",
            "390/390 [==============================] - 319s 817ms/step - loss: 2.1882 - acc: 0.6610 - val_loss: 3.3314 - val_acc: 0.4787\n",
            "Epoch 18/35\n",
            "390/390 [==============================] - 319s 817ms/step - loss: 1.9976 - acc: 0.7042 - val_loss: 2.9416 - val_acc: 0.5485\n",
            "Epoch 19/35\n",
            "390/390 [==============================] - 318s 816ms/step - loss: 1.7887 - acc: 0.7495 - val_loss: 2.9278 - val_acc: 0.5483\n",
            "Epoch 20/35\n",
            "390/390 [==============================] - 316s 811ms/step - loss: 1.5979 - acc: 0.7931 - val_loss: 2.8847 - val_acc: 0.5534\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/35\n",
            "390/390 [==============================] - 317s 813ms/step - loss: 1.4646 - acc: 0.8256 - val_loss: 2.8391 - val_acc: 0.5629\n",
            "Epoch 22/35\n",
            "390/390 [==============================] - 317s 812ms/step - loss: 1.4829 - acc: 0.8171 - val_loss: 2.9425 - val_acc: 0.5448\n",
            "Epoch 23/35\n",
            "390/390 [==============================] - 316s 810ms/step - loss: 1.6294 - acc: 0.7696 - val_loss: 3.1275 - val_acc: 0.5141\n",
            "Epoch 24/35\n",
            "390/390 [==============================] - 315s 808ms/step - loss: 1.8786 - acc: 0.7069 - val_loss: 3.3994 - val_acc: 0.4602\n",
            "Epoch 25/35\n",
            "390/390 [==============================] - 318s 816ms/step - loss: 2.1350 - acc: 0.6547 - val_loss: 3.3809 - val_acc: 0.4620\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/35\n",
            "390/390 [==============================] - 317s 814ms/step - loss: 2.3259 - acc: 0.6225 - val_loss: 3.1104 - val_acc: 0.5042\n",
            "Epoch 27/35\n",
            "390/390 [==============================] - 317s 812ms/step - loss: 2.2506 - acc: 0.6486 - val_loss: 3.2724 - val_acc: 0.4868\n",
            "Epoch 28/35\n",
            "390/390 [==============================] - 316s 811ms/step - loss: 2.0544 - acc: 0.6931 - val_loss: 3.2367 - val_acc: 0.4968\n",
            "Epoch 29/35\n",
            "390/390 [==============================] - 316s 810ms/step - loss: 1.8449 - acc: 0.7404 - val_loss: 3.0337 - val_acc: 0.5342\n",
            "Epoch 30/35\n",
            "390/390 [==============================] - 316s 809ms/step - loss: 1.6388 - acc: 0.7870 - val_loss: 2.8609 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/35\n",
            "390/390 [==============================] - 317s 814ms/step - loss: 1.4779 - acc: 0.8266 - val_loss: 2.8705 - val_acc: 0.5610\n",
            "Epoch 32/35\n",
            "390/390 [==============================] - 318s 815ms/step - loss: 1.4544 - acc: 0.8287 - val_loss: 3.0115 - val_acc: 0.5444\n",
            "Epoch 33/35\n",
            "390/390 [==============================] - 318s 815ms/step - loss: 1.5692 - acc: 0.7928 - val_loss: 3.2421 - val_acc: 0.4936\n",
            "Epoch 34/35\n",
            "390/390 [==============================] - 319s 819ms/step - loss: 1.8035 - acc: 0.7286 - val_loss: 3.1651 - val_acc: 0.4956\n",
            "Epoch 35/35\n",
            "390/390 [==============================] - 317s 813ms/step - loss: 2.0751 - acc: 0.6685 - val_loss: 3.7149 - val_acc: 0.4330\n",
            "\n",
            "Epoch 00035: saving model to ../checkpoints/check.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9lNzQq5Gakh",
        "colab_type": "text"
      },
      "source": [
        "## Total epochs = 235"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H07vkJz5mo07",
        "colab_type": "code",
        "outputId": "474e857c-5d7c-410d-fe2b-7ada19cb4ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1510
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 256,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 256,\n",
        "  epochs=35,\n",
        "  max_queue_size=128 * 4,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "390/390 [==============================] - 370s 950ms/step - loss: 1.9121 - acc: 0.7196 - val_loss: 2.9562 - val_acc: 0.5369\n",
            "Epoch 2/35\n",
            "390/390 [==============================] - 311s 797ms/step - loss: 1.6409 - acc: 0.7804 - val_loss: 2.9299 - val_acc: 0.5489\n",
            "Epoch 3/35\n",
            "390/390 [==============================] - 310s 794ms/step - loss: 1.7659 - acc: 0.7413 - val_loss: 3.3198 - val_acc: 0.4808\n",
            "Epoch 4/35\n",
            "390/390 [==============================] - 310s 794ms/step - loss: 2.0254 - acc: 0.6795 - val_loss: 3.7144 - val_acc: 0.4312\n",
            "Epoch 5/35\n",
            "390/390 [==============================] - 309s 793ms/step - loss: 2.2597 - acc: 0.6370 - val_loss: 3.9806 - val_acc: 0.3922\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "390/390 [==============================] - 310s 795ms/step - loss: 2.3488 - acc: 0.6288 - val_loss: 3.3549 - val_acc: 0.4725\n",
            "Epoch 7/35\n",
            "390/390 [==============================] - 308s 791ms/step - loss: 2.1537 - acc: 0.6766 - val_loss: 3.0887 - val_acc: 0.5237\n",
            "Epoch 8/35\n",
            "390/390 [==============================] - 307s 787ms/step - loss: 1.9524 - acc: 0.7204 - val_loss: 2.9878 - val_acc: 0.5432\n",
            "Epoch 9/35\n",
            "390/390 [==============================] - 313s 803ms/step - loss: 1.7297 - acc: 0.7713 - val_loss: 3.0190 - val_acc: 0.5422\n",
            "Epoch 10/35\n",
            "390/390 [==============================] - 315s 809ms/step - loss: 1.5339 - acc: 0.8178 - val_loss: 2.9574 - val_acc: 0.5625\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/35\n",
            "390/390 [==============================] - 313s 803ms/step - loss: 1.4245 - acc: 0.8453 - val_loss: 2.9832 - val_acc: 0.5554\n",
            "Epoch 12/35\n",
            "390/390 [==============================] - 314s 804ms/step - loss: 1.4960 - acc: 0.8185 - val_loss: 3.2020 - val_acc: 0.5200\n",
            "Epoch 13/35\n",
            "390/390 [==============================] - 315s 809ms/step - loss: 1.6651 - acc: 0.7688 - val_loss: 3.2585 - val_acc: 0.4998\n",
            "Epoch 14/35\n",
            "390/390 [==============================] - 315s 808ms/step - loss: 1.9582 - acc: 0.6958 - val_loss: 3.2965 - val_acc: 0.4887\n",
            "Epoch 15/35\n",
            "390/390 [==============================] - 317s 814ms/step - loss: 2.2124 - acc: 0.6488 - val_loss: 3.2732 - val_acc: 0.4910\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/35\n",
            "390/390 [==============================] - 325s 834ms/step - loss: 2.3604 - acc: 0.6262 - val_loss: 3.5862 - val_acc: 0.4455\n",
            "Epoch 17/35\n",
            "390/390 [==============================] - 325s 834ms/step - loss: 2.2191 - acc: 0.6646 - val_loss: 3.2600 - val_acc: 0.5047\n",
            "Epoch 18/35\n",
            "390/390 [==============================] - 325s 833ms/step - loss: 2.0074 - acc: 0.7126 - val_loss: 3.6268 - val_acc: 0.4638\n",
            "Epoch 19/35\n",
            "390/390 [==============================] - 325s 832ms/step - loss: 1.7817 - acc: 0.7633 - val_loss: 3.1084 - val_acc: 0.5316\n",
            "Epoch 20/35\n",
            "390/390 [==============================] - 325s 833ms/step - loss: 1.5752 - acc: 0.8105 - val_loss: 3.0422 - val_acc: 0.5510\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/35\n",
            "390/390 [==============================] - 324s 830ms/step - loss: 1.4297 - acc: 0.8486 - val_loss: 2.9813 - val_acc: 0.5559\n",
            "Epoch 22/35\n",
            "390/390 [==============================] - 324s 831ms/step - loss: 1.4539 - acc: 0.8372 - val_loss: 3.1624 - val_acc: 0.5305\n",
            "Epoch 23/35\n",
            "390/390 [==============================] - 324s 831ms/step - loss: 1.6118 - acc: 0.7855 - val_loss: 3.2215 - val_acc: 0.5127\n",
            "Epoch 24/35\n",
            "390/390 [==============================] - 325s 833ms/step - loss: 1.8864 - acc: 0.7166 - val_loss: 3.4004 - val_acc: 0.4745\n",
            "Epoch 25/35\n",
            "390/390 [==============================] - 326s 836ms/step - loss: 2.1614 - acc: 0.6584 - val_loss: 3.3242 - val_acc: 0.4804\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/35\n",
            "390/390 [==============================] - 329s 844ms/step - loss: 2.3618 - acc: 0.6271 - val_loss: 3.3003 - val_acc: 0.4927\n",
            "Epoch 27/35\n",
            "390/390 [==============================] - 330s 847ms/step - loss: 2.2654 - acc: 0.6567 - val_loss: 3.7295 - val_acc: 0.4474\n",
            "Epoch 28/35\n",
            "390/390 [==============================] - 328s 840ms/step - loss: 2.0666 - acc: 0.7017 - val_loss: 3.4516 - val_acc: 0.4775\n",
            "Epoch 29/35\n",
            "390/390 [==============================] - 328s 842ms/step - loss: 1.8486 - acc: 0.7504 - val_loss: 3.1479 - val_acc: 0.5294\n",
            "Epoch 30/35\n",
            "390/390 [==============================] - 328s 841ms/step - loss: 1.6228 - acc: 0.8030 - val_loss: 3.0087 - val_acc: 0.5520\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/35\n",
            "390/390 [==============================] - 327s 840ms/step - loss: 1.4592 - acc: 0.8438 - val_loss: 2.9746 - val_acc: 0.5610\n",
            "Epoch 32/35\n",
            "390/390 [==============================] - 327s 838ms/step - loss: 1.4324 - acc: 0.8471 - val_loss: 3.1266 - val_acc: 0.5458\n",
            "Epoch 33/35\n",
            "390/390 [==============================] - 326s 837ms/step - loss: 1.5525 - acc: 0.8073 - val_loss: 3.3579 - val_acc: 0.5058\n",
            "Epoch 34/35\n",
            "390/390 [==============================] - 326s 835ms/step - loss: 1.8073 - acc: 0.7364 - val_loss: 3.6335 - val_acc: 0.4521\n",
            "Epoch 35/35\n",
            "390/390 [==============================] - 326s 836ms/step - loss: 2.0965 - acc: 0.6722 - val_loss: 3.7022 - val_acc: 0.4444\n",
            "\n",
            "Epoch 00035: saving model to ../checkpoints/check.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zslaxCwYrmv",
        "colab_type": "text"
      },
      "source": [
        "## Total Epochs = 270"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT__J8EWYtbi",
        "colab_type": "code",
        "outputId": "47ad293d-909d-4a37-9242-51d4c2b5cb9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1565
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 256,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 256,\n",
        "  epochs=35,\n",
        "  max_queue_size=128 * 4,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')\n",
        "model.save(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "  2/390 [..............................] - ETA: 42:06 - loss: 2.4083 - acc: 0.6172  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.801945). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 389s 997ms/step - loss: 1.9558 - acc: 0.7180 - val_loss: 2.9219 - val_acc: 0.5592\n",
            "Epoch 2/35\n",
            "390/390 [==============================] - 324s 831ms/step - loss: 1.6414 - acc: 0.7905 - val_loss: 3.1314 - val_acc: 0.5303\n",
            "Epoch 3/35\n",
            "390/390 [==============================] - 327s 838ms/step - loss: 1.7588 - acc: 0.7549 - val_loss: 3.4664 - val_acc: 0.4658\n",
            "Epoch 4/35\n",
            "390/390 [==============================] - 330s 845ms/step - loss: 2.0339 - acc: 0.6872 - val_loss: 3.5265 - val_acc: 0.4595\n",
            "Epoch 5/35\n",
            "390/390 [==============================] - 332s 852ms/step - loss: 2.2841 - acc: 0.6418 - val_loss: 3.6350 - val_acc: 0.4517\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "390/390 [==============================] - 314s 805ms/step - loss: 2.3787 - acc: 0.6332 - val_loss: 3.3773 - val_acc: 0.4909\n",
            "Epoch 7/35\n",
            "390/390 [==============================] - 313s 803ms/step - loss: 2.1779 - acc: 0.6815 - val_loss: 3.5272 - val_acc: 0.4609\n",
            "Epoch 8/35\n",
            "390/390 [==============================] - 315s 808ms/step - loss: 1.9570 - acc: 0.7294 - val_loss: 3.3398 - val_acc: 0.5012\n",
            "Epoch 9/35\n",
            "390/390 [==============================] - 315s 807ms/step - loss: 1.7258 - acc: 0.7797 - val_loss: 3.2651 - val_acc: 0.5218\n",
            "Epoch 10/35\n",
            "390/390 [==============================] - 327s 838ms/step - loss: 1.5210 - acc: 0.8301 - val_loss: 3.0122 - val_acc: 0.5586\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/35\n",
            "390/390 [==============================] - 333s 854ms/step - loss: 1.4197 - acc: 0.8566 - val_loss: 3.0959 - val_acc: 0.5461\n",
            "Epoch 12/35\n",
            "390/390 [==============================] - 334s 856ms/step - loss: 1.4713 - acc: 0.8352 - val_loss: 3.2167 - val_acc: 0.5307\n",
            "Epoch 13/35\n",
            "390/390 [==============================] - 333s 854ms/step - loss: 1.6545 - acc: 0.7780 - val_loss: 3.2537 - val_acc: 0.5033\n",
            "Epoch 14/35\n",
            "390/390 [==============================] - 332s 852ms/step - loss: 1.9698 - acc: 0.7014 - val_loss: 3.5334 - val_acc: 0.4622\n",
            "Epoch 15/35\n",
            "390/390 [==============================] - 333s 853ms/step - loss: 2.2319 - acc: 0.6514 - val_loss: 3.4136 - val_acc: 0.4684\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/35\n",
            "390/390 [==============================] - 333s 853ms/step - loss: 2.4008 - acc: 0.6274 - val_loss: 3.6862 - val_acc: 0.4460\n",
            "Epoch 17/35\n",
            "390/390 [==============================] - 332s 852ms/step - loss: 2.2411 - acc: 0.6684 - val_loss: 3.6845 - val_acc: 0.4515\n",
            "Epoch 18/35\n",
            "390/390 [==============================] - 333s 853ms/step - loss: 2.0301 - acc: 0.7166 - val_loss: 3.0221 - val_acc: 0.5503\n",
            "Epoch 19/35\n",
            "390/390 [==============================] - 333s 854ms/step - loss: 1.7789 - acc: 0.7720 - val_loss: 3.1364 - val_acc: 0.5356\n",
            "Epoch 20/35\n",
            "390/390 [==============================] - 332s 852ms/step - loss: 1.5757 - acc: 0.8189 - val_loss: 3.0419 - val_acc: 0.5532\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/35\n",
            "390/390 [==============================] - 331s 848ms/step - loss: 1.4318 - acc: 0.8571 - val_loss: 3.0372 - val_acc: 0.5559\n",
            "Epoch 22/35\n",
            "390/390 [==============================] - 332s 851ms/step - loss: 1.4435 - acc: 0.8479 - val_loss: 3.0486 - val_acc: 0.5528\n",
            "Epoch 23/35\n",
            "390/390 [==============================] - 332s 851ms/step - loss: 1.5941 - acc: 0.7976 - val_loss: 3.7594 - val_acc: 0.4538\n",
            "Epoch 24/35\n",
            "390/390 [==============================] - 332s 850ms/step - loss: 1.8833 - acc: 0.7224 - val_loss: 3.4994 - val_acc: 0.4586\n",
            "Epoch 25/35\n",
            "390/390 [==============================] - 332s 851ms/step - loss: 2.1735 - acc: 0.6610 - val_loss: 3.7039 - val_acc: 0.4412\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/35\n",
            "390/390 [==============================] - 333s 854ms/step - loss: 2.3810 - acc: 0.6293 - val_loss: 3.8302 - val_acc: 0.4292\n",
            "Epoch 27/35\n",
            "390/390 [==============================] - 334s 855ms/step - loss: 2.3018 - acc: 0.6560 - val_loss: 4.1462 - val_acc: 0.4032\n",
            "Epoch 28/35\n",
            "390/390 [==============================] - 333s 855ms/step - loss: 2.0660 - acc: 0.7114 - val_loss: 3.1764 - val_acc: 0.5292\n",
            "Epoch 29/35\n",
            "390/390 [==============================] - 332s 852ms/step - loss: 1.8447 - acc: 0.7582 - val_loss: 3.1646 - val_acc: 0.5391\n",
            "Epoch 30/35\n",
            "390/390 [==============================] - 328s 842ms/step - loss: 1.6184 - acc: 0.8112 - val_loss: 3.0771 - val_acc: 0.5495\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 31/35\n",
            "390/390 [==============================] - 323s 828ms/step - loss: 1.4470 - acc: 0.8538 - val_loss: 3.0436 - val_acc: 0.5576\n",
            "Epoch 32/35\n",
            "390/390 [==============================] - 325s 832ms/step - loss: 1.4249 - acc: 0.8567 - val_loss: 3.2675 - val_acc: 0.5241\n",
            "Epoch 33/35\n",
            "390/390 [==============================] - 329s 844ms/step - loss: 1.5321 - acc: 0.8162 - val_loss: 3.3008 - val_acc: 0.5134\n",
            "Epoch 34/35\n",
            "390/390 [==============================] - 334s 857ms/step - loss: 1.8021 - acc: 0.7433 - val_loss: 3.5560 - val_acc: 0.4580\n",
            "Epoch 35/35\n",
            "390/390 [==============================] - 333s 853ms/step - loss: 2.1011 - acc: 0.6764 - val_loss: 3.9388 - val_acc: 0.3983\n",
            "\n",
            "Epoch 00035: saving model to ../checkpoints/check.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obGCG3Ov9qID",
        "colab_type": "text"
      },
      "source": [
        "## Switched to Learning Rate Decay\n",
        "---\n",
        "\n",
        "## Total Epochs = 305"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1G5uV6dY1sG",
        "colab_type": "code",
        "outputId": "db69bcb9-4e42-425d-d47e-18b1b8961ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.lr, 0.0005)\n",
        "print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 256,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 256,\n",
        "  epochs=35,\n",
        "  max_queue_size=128 * 4,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Old Learning Rate: 0.0004428571555763483\n",
            "New Learning Rate: 0.0005000000237487257\n",
            "Epoch 1/35\n",
            "390/390 [==============================] - 389s 999ms/step - loss: 1.7597 - acc: 0.7740 - val_loss: 3.0878 - val_acc: 0.5342\n",
            "Epoch 2/35\n",
            "390/390 [==============================] - 310s 794ms/step - loss: 1.7282 - acc: 0.7818 - val_loss: 3.0648 - val_acc: 0.5401\n",
            "Epoch 3/35\n",
            "390/390 [==============================] - 320s 822ms/step - loss: 1.7080 - acc: 0.7868 - val_loss: 3.0454 - val_acc: 0.5440\n",
            "Epoch 4/35\n",
            "390/390 [==============================] - 325s 834ms/step - loss: 1.6845 - acc: 0.7930 - val_loss: 3.0602 - val_acc: 0.5422\n",
            "Epoch 5/35\n",
            "390/390 [==============================] - 328s 840ms/step - loss: 1.6645 - acc: 0.7985 - val_loss: 3.0622 - val_acc: 0.5436\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/35\n",
            "109/390 [=======>......................] - ETA: 3:42 - loss: 1.6520 - acc: 0.8021"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktcl_bqxidmG",
        "colab_type": "text"
      },
      "source": [
        "## Colab crashed after just 5 epochs!\n",
        "---\n",
        "## Total epochs = 310"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1WQCZ4BH_dG",
        "colab_type": "code",
        "outputId": "503a80c3-e2c0-41a6-f355-a0991f116ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1405
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.lr, 0.0005)\n",
        "print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 256,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 256,\n",
        "  epochs=30,\n",
        "  max_queue_size=128 * 4,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Old Learning Rate: 0.0004428571555763483\n",
            "New Learning Rate: 0.0005000000237487257\n",
            "Epoch 1/30\n",
            "390/390 [==============================] - 399s 1s/step - loss: 1.6510 - acc: 0.8014 - val_loss: 3.0383 - val_acc: 0.5471\n",
            "Epoch 2/30\n",
            "390/390 [==============================] - 313s 802ms/step - loss: 1.6337 - acc: 0.8072 - val_loss: 3.0499 - val_acc: 0.5472\n",
            "Epoch 3/30\n",
            "390/390 [==============================] - 334s 857ms/step - loss: 1.6212 - acc: 0.8091 - val_loss: 3.0344 - val_acc: 0.5509\n",
            "Epoch 4/30\n",
            "390/390 [==============================] - 334s 857ms/step - loss: 1.6101 - acc: 0.8109 - val_loss: 3.0470 - val_acc: 0.5501\n",
            "Epoch 5/30\n",
            "390/390 [==============================] - 334s 857ms/step - loss: 1.6021 - acc: 0.8132 - val_loss: 3.0469 - val_acc: 0.5482\n",
            "\n",
            "Epoch 00005: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 6/30\n",
            "390/390 [==============================] - 335s 859ms/step - loss: 1.5932 - acc: 0.8157 - val_loss: 3.0486 - val_acc: 0.5500\n",
            "Epoch 7/30\n",
            "390/390 [==============================] - 338s 867ms/step - loss: 1.5808 - acc: 0.8193 - val_loss: 3.0369 - val_acc: 0.5497\n",
            "Epoch 8/30\n",
            "390/390 [==============================] - 341s 875ms/step - loss: 1.5694 - acc: 0.8231 - val_loss: 3.0338 - val_acc: 0.5516\n",
            "Epoch 9/30\n",
            "390/390 [==============================] - 341s 875ms/step - loss: 1.5638 - acc: 0.8237 - val_loss: 3.0123 - val_acc: 0.5550\n",
            "Epoch 10/30\n",
            "390/390 [==============================] - 338s 867ms/step - loss: 1.5573 - acc: 0.8260 - val_loss: 3.0429 - val_acc: 0.5508\n",
            "\n",
            "Epoch 00010: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 11/30\n",
            "390/390 [==============================] - 342s 876ms/step - loss: 1.5558 - acc: 0.8267 - val_loss: 3.0254 - val_acc: 0.5542\n",
            "Epoch 12/30\n",
            "390/390 [==============================] - 341s 874ms/step - loss: 1.5460 - acc: 0.8278 - val_loss: 3.0260 - val_acc: 0.5541\n",
            "Epoch 13/30\n",
            "390/390 [==============================] - 341s 873ms/step - loss: 1.5410 - acc: 0.8303 - val_loss: 3.0225 - val_acc: 0.5550\n",
            "Epoch 14/30\n",
            "390/390 [==============================] - 338s 868ms/step - loss: 1.5355 - acc: 0.8296 - val_loss: 3.0250 - val_acc: 0.5571\n",
            "Epoch 15/30\n",
            "390/390 [==============================] - 338s 867ms/step - loss: 1.5288 - acc: 0.8320 - val_loss: 3.0421 - val_acc: 0.5509\n",
            "\n",
            "Epoch 00015: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 16/30\n",
            "390/390 [==============================] - 338s 868ms/step - loss: 1.5307 - acc: 0.8314 - val_loss: 3.0515 - val_acc: 0.5495\n",
            "Epoch 17/30\n",
            "390/390 [==============================] - 335s 858ms/step - loss: 1.5199 - acc: 0.8356 - val_loss: 3.0230 - val_acc: 0.5557\n",
            "Epoch 18/30\n",
            "390/390 [==============================] - 333s 855ms/step - loss: 1.5199 - acc: 0.8352 - val_loss: 3.0198 - val_acc: 0.5555\n",
            "Epoch 19/30\n",
            "390/390 [==============================] - 336s 861ms/step - loss: 1.5102 - acc: 0.8371 - val_loss: 3.0457 - val_acc: 0.5536\n",
            "Epoch 20/30\n",
            "390/390 [==============================] - 337s 864ms/step - loss: 1.5122 - acc: 0.8369 - val_loss: 3.0098 - val_acc: 0.5560\n",
            "\n",
            "Epoch 00020: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 21/30\n",
            "390/390 [==============================] - 337s 864ms/step - loss: 1.5071 - acc: 0.8382 - val_loss: 3.0328 - val_acc: 0.5524\n",
            "Epoch 22/30\n",
            "390/390 [==============================] - 338s 867ms/step - loss: 1.5042 - acc: 0.8381 - val_loss: 3.0328 - val_acc: 0.5532\n",
            "Epoch 23/30\n",
            "390/390 [==============================] - 338s 866ms/step - loss: 1.5067 - acc: 0.8387 - val_loss: 3.0564 - val_acc: 0.5510\n",
            "Epoch 24/30\n",
            "390/390 [==============================] - 336s 862ms/step - loss: 1.4992 - acc: 0.8394 - val_loss: 3.0480 - val_acc: 0.5522\n",
            "Epoch 25/30\n",
            "390/390 [==============================] - 336s 862ms/step - loss: 1.4955 - acc: 0.8412 - val_loss: 3.0586 - val_acc: 0.5497\n",
            "\n",
            "Epoch 00025: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 26/30\n",
            "390/390 [==============================] - 338s 866ms/step - loss: 1.4964 - acc: 0.8405 - val_loss: 3.0262 - val_acc: 0.5576\n",
            "Epoch 27/30\n",
            "390/390 [==============================] - 338s 867ms/step - loss: 1.4910 - acc: 0.8421 - val_loss: 3.0404 - val_acc: 0.5530\n",
            "Epoch 28/30\n",
            "390/390 [==============================] - 339s 870ms/step - loss: 1.4932 - acc: 0.8417 - val_loss: 3.0192 - val_acc: 0.5559\n",
            "Epoch 29/30\n",
            "390/390 [==============================] - 337s 864ms/step - loss: 1.4907 - acc: 0.8415 - val_loss: 3.0248 - val_acc: 0.5568\n",
            "Epoch 30/30\n",
            "390/390 [==============================] - 339s 869ms/step - loss: 1.4939 - acc: 0.8407 - val_loss: 3.0497 - val_acc: 0.5502\n",
            "\n",
            "Epoch 00030: saving model to ../checkpoints/check.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpJ1KnZohfZv",
        "colab_type": "text"
      },
      "source": [
        "## Achieved 55.76 Validation Accuracy on Epoch 336\n",
        "\n",
        "---\n",
        "## Total Epochs = 340\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDmHG3y9D1UH",
        "colab_type": "code",
        "outputId": "435752f7-4cd2-4a9c-8680-aad325bd6b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1012
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.lr, 0.000002)\n",
        "print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.momentum, 0.99)\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 64,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 64,\n",
        "  epochs=30,\n",
        "  max_queue_size=128,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old Learning Rate: 0.00037142858491279185\n",
            "New Learning Rate: 1.9999999949504854e-06\n",
            "Epoch 1/30\n",
            "1562/1562 [==============================] - 632s 405ms/step - loss: 1.9404 - acc: 0.7078 - val_loss: 2.8872 - val_acc: 0.5665\n",
            "Epoch 2/30\n",
            "1562/1562 [==============================] - 580s 371ms/step - loss: 1.8846 - acc: 0.7210 - val_loss: 2.9150 - val_acc: 0.5613\n",
            "Epoch 3/30\n",
            "1562/1562 [==============================] - 615s 394ms/step - loss: 1.8518 - acc: 0.7263 - val_loss: 2.8752 - val_acc: 0.5668\n",
            "Epoch 4/30\n",
            "1562/1562 [==============================] - 618s 396ms/step - loss: 1.8309 - acc: 0.7327 - val_loss: 2.8589 - val_acc: 0.5713\n",
            "\n",
            "Epoch 00004: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 5/30\n",
            "1562/1562 [==============================] - 614s 393ms/step - loss: 1.8112 - acc: 0.7362 - val_loss: 2.8604 - val_acc: 0.5706\n",
            "Epoch 6/30\n",
            "1562/1562 [==============================] - 614s 393ms/step - loss: 1.8009 - acc: 0.7392 - val_loss: 2.8916 - val_acc: 0.5666\n",
            "Epoch 7/30\n",
            "1562/1562 [==============================] - 612s 392ms/step - loss: 1.7903 - acc: 0.7413 - val_loss: 2.8812 - val_acc: 0.5666\n",
            "Epoch 8/30\n",
            "1562/1562 [==============================] - 613s 393ms/step - loss: 1.7838 - acc: 0.7436 - val_loss: 2.8853 - val_acc: 0.5682\n",
            "Epoch 9/30\n",
            "1562/1562 [==============================] - 617s 395ms/step - loss: 1.7705 - acc: 0.7451 - val_loss: 2.9011 - val_acc: 0.5653\n",
            "\n",
            "Epoch 00009: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 10/30\n",
            "1562/1562 [==============================] - 618s 396ms/step - loss: 1.7702 - acc: 0.7458 - val_loss: 2.8687 - val_acc: 0.5713\n",
            "Epoch 11/30\n",
            "1562/1562 [==============================] - 621s 397ms/step - loss: 1.7560 - acc: 0.7481 - val_loss: 2.9140 - val_acc: 0.5623\n",
            "Epoch 12/30\n",
            "1562/1562 [==============================] - 623s 399ms/step - loss: 1.7539 - acc: 0.7486 - val_loss: 2.8640 - val_acc: 0.5715\n",
            "Epoch 13/30\n",
            "1562/1562 [==============================] - 621s 398ms/step - loss: 1.7512 - acc: 0.7509 - val_loss: 2.8316 - val_acc: 0.5760\n",
            "Epoch 14/30\n",
            "1562/1562 [==============================] - 622s 398ms/step - loss: 1.7430 - acc: 0.7529 - val_loss: 2.8909 - val_acc: 0.5671\n",
            "\n",
            "Epoch 00014: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 15/30\n",
            "1562/1562 [==============================] - 620s 397ms/step - loss: 1.7452 - acc: 0.7528 - val_loss: 2.8391 - val_acc: 0.5762\n",
            "Epoch 16/30\n",
            "1562/1562 [==============================] - 621s 397ms/step - loss: 1.7420 - acc: 0.7542 - val_loss: 2.8459 - val_acc: 0.5745\n",
            "Epoch 17/30\n",
            "1562/1562 [==============================] - 629s 403ms/step - loss: 1.7360 - acc: 0.7539 - val_loss: 2.9057 - val_acc: 0.5651\n",
            "Epoch 18/30\n",
            "1562/1562 [==============================] - 621s 398ms/step - loss: 1.7369 - acc: 0.7544 - val_loss: 2.8736 - val_acc: 0.5692\n",
            "Epoch 19/30\n",
            "1562/1562 [==============================] - 625s 400ms/step - loss: 1.7292 - acc: 0.7558 - val_loss: 2.8761 - val_acc: 0.5698\n",
            "\n",
            "Epoch 00019: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 20/30\n",
            "1562/1562 [==============================] - 614s 393ms/step - loss: 1.7305 - acc: 0.7562 - val_loss: 2.8622 - val_acc: 0.5698\n",
            "Epoch 21/30\n",
            "1562/1562 [==============================] - 620s 397ms/step - loss: 1.7243 - acc: 0.7570 - val_loss: 2.8130 - val_acc: 0.5779\n",
            "Epoch 22/30\n",
            "1562/1562 [==============================] - 615s 394ms/step - loss: 1.7210 - acc: 0.7585 - val_loss: 2.8340 - val_acc: 0.5770\n",
            "Epoch 23/30\n",
            " 161/1562 [==>...........................] - ETA: 8:42 - loss: 1.7250 - acc: 0.7594"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uJwfvmaaljv",
        "colab_type": "text"
      },
      "source": [
        "## Achieved Validation Accuracy of 57.79 on Epoch 361\n",
        "\n",
        "---\n",
        "\n",
        "## Total epochs = 365"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC9uw5mtahUW",
        "colab_type": "code",
        "outputId": "f926f66f-763f-4c08-c287-47739ad73052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1332
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.lr, 0.000002)\n",
        "print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.momentum, 0.99)\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 128,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 128,\n",
        "  epochs=30,\n",
        "  max_queue_size=128 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")\n",
        "model.save('model1.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old Learning Rate: 1.7714285149850184e-07\n",
            "New Learning Rate: 1.9999999949504854e-06\n",
            "Epoch 1/30\n",
            "781/781 [==============================] - 480s 615ms/step - loss: 1.6299 - acc: 0.7820 - val_loss: 2.8289 - val_acc: 0.5747\n",
            "Epoch 2/30\n",
            "781/781 [==============================] - 417s 534ms/step - loss: 1.6321 - acc: 0.7814 - val_loss: 2.8591 - val_acc: 0.5722\n",
            "Epoch 3/30\n",
            "781/781 [==============================] - 455s 583ms/step - loss: 1.6360 - acc: 0.7792 - val_loss: 2.8841 - val_acc: 0.5675\n",
            "Epoch 4/30\n",
            "781/781 [==============================] - 456s 584ms/step - loss: 1.6325 - acc: 0.7813 - val_loss: 2.8603 - val_acc: 0.5694\n",
            "\n",
            "Epoch 00004: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 5/30\n",
            "781/781 [==============================] - 457s 585ms/step - loss: 1.6283 - acc: 0.7820 - val_loss: 2.8525 - val_acc: 0.5721\n",
            "Epoch 6/30\n",
            "781/781 [==============================] - 458s 586ms/step - loss: 1.6267 - acc: 0.7836 - val_loss: 2.8594 - val_acc: 0.5705\n",
            "Epoch 7/30\n",
            "781/781 [==============================] - 457s 585ms/step - loss: 1.6301 - acc: 0.7810 - val_loss: 2.8375 - val_acc: 0.5726\n",
            "Epoch 8/30\n",
            "781/781 [==============================] - 457s 586ms/step - loss: 1.6304 - acc: 0.7814 - val_loss: 2.8605 - val_acc: 0.5695\n",
            "Epoch 9/30\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6300 - acc: 0.7823 - val_loss: 2.8457 - val_acc: 0.5715\n",
            "\n",
            "Epoch 00009: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 10/30\n",
            "781/781 [==============================] - 459s 587ms/step - loss: 1.6252 - acc: 0.7822 - val_loss: 2.8248 - val_acc: 0.5783\n",
            "Epoch 11/30\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6300 - acc: 0.7813 - val_loss: 2.8602 - val_acc: 0.5705\n",
            "Epoch 12/30\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6359 - acc: 0.7795 - val_loss: 2.8631 - val_acc: 0.5707\n",
            "Epoch 13/30\n",
            "781/781 [==============================] - 460s 588ms/step - loss: 1.6340 - acc: 0.7808 - val_loss: 2.8296 - val_acc: 0.5762\n",
            "Epoch 14/30\n",
            "781/781 [==============================] - 455s 583ms/step - loss: 1.6289 - acc: 0.7816 - val_loss: 2.8537 - val_acc: 0.5694\n",
            "\n",
            "Epoch 00014: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 15/30\n",
            "781/781 [==============================] - 454s 582ms/step - loss: 1.6343 - acc: 0.7812 - val_loss: 2.8554 - val_acc: 0.5711\n",
            "Epoch 16/30\n",
            "781/781 [==============================] - 456s 584ms/step - loss: 1.6287 - acc: 0.7826 - val_loss: 2.8605 - val_acc: 0.5705\n",
            "Epoch 17/30\n",
            "781/781 [==============================] - 460s 589ms/step - loss: 1.6294 - acc: 0.7818 - val_loss: 2.8326 - val_acc: 0.5751\n",
            "Epoch 18/30\n",
            "781/781 [==============================] - 464s 594ms/step - loss: 1.6314 - acc: 0.7811 - val_loss: 2.8627 - val_acc: 0.5696\n",
            "Epoch 19/30\n",
            "781/781 [==============================] - 458s 586ms/step - loss: 1.6344 - acc: 0.7800 - val_loss: 2.8232 - val_acc: 0.5756\n",
            "\n",
            "Epoch 00019: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 20/30\n",
            "781/781 [==============================] - 451s 578ms/step - loss: 1.6373 - acc: 0.7794 - val_loss: 2.8606 - val_acc: 0.5687\n",
            "Epoch 21/30\n",
            "781/781 [==============================] - 451s 577ms/step - loss: 1.6344 - acc: 0.7806 - val_loss: 2.8399 - val_acc: 0.5748\n",
            "Epoch 22/30\n",
            "781/781 [==============================] - 452s 579ms/step - loss: 1.6311 - acc: 0.7831 - val_loss: 2.8398 - val_acc: 0.5729\n",
            "Epoch 23/30\n",
            "781/781 [==============================] - 452s 578ms/step - loss: 1.6280 - acc: 0.7821 - val_loss: 2.8529 - val_acc: 0.5728\n",
            "Epoch 24/30\n",
            "781/781 [==============================] - 451s 578ms/step - loss: 1.6286 - acc: 0.7809 - val_loss: 2.8596 - val_acc: 0.5719\n",
            "\n",
            "Epoch 00024: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 25/30\n",
            "781/781 [==============================] - 450s 576ms/step - loss: 1.6309 - acc: 0.7813 - val_loss: 2.8562 - val_acc: 0.5710\n",
            "Epoch 26/30\n",
            "781/781 [==============================] - 451s 578ms/step - loss: 1.6304 - acc: 0.7807 - val_loss: 2.8421 - val_acc: 0.5734\n",
            "Epoch 27/30\n",
            "781/781 [==============================] - 455s 583ms/step - loss: 1.6325 - acc: 0.7823 - val_loss: 2.8311 - val_acc: 0.5745\n",
            "Epoch 28/30\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6300 - acc: 0.7805 - val_loss: 2.8150 - val_acc: 0.5740\n",
            "Epoch 29/30\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6338 - acc: 0.7801 - val_loss: 2.8412 - val_acc: 0.5728\n",
            "\n",
            "Epoch 00029: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 30/30\n",
            "781/781 [==============================] - 458s 586ms/step - loss: 1.6297 - acc: 0.7807 - val_loss: 2.8739 - val_acc: 0.5688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9w0J8qwiPOW",
        "colab_type": "text"
      },
      "source": [
        "## Achieved Validation Accuracy of 57.83 on Epoch 375\n",
        "\n",
        "---\n",
        "\n",
        "## Total Epochs = 395"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq7pV_TkT2Qo",
        "colab_type": "code",
        "outputId": "61b3121d-d112-4e41-c43c-5406c6dfb558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model = load_model(checkpoint_path)\n",
        "print(f'Old Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.lr, 2e-08)\n",
        "print(f'New Learning Rate: {K.get_value(model.optimizer.lr)}')\n",
        "K.set_value(model.optimizer.momentum, 0.99)\n",
        "\n",
        "model.fit_generator(\n",
        "  train_generator,\n",
        "  steps_per_epoch=100000 // 128,\n",
        "  validation_data=val_generator,\n",
        "  validation_steps=10000 // 128,\n",
        "  epochs=10,\n",
        "  max_queue_size=128 * 2,\n",
        "  callbacks=callbacks, verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old Learning Rate: 1.9428571818025375e-07\n",
            "New Learning Rate: 1.999999987845058e-08\n",
            "Epoch 1/10\n",
            "781/781 [==============================] - 489s 625ms/step - loss: 1.6256 - acc: 0.7826 - val_loss: 2.8618 - val_acc: 0.5682\n",
            "Epoch 2/10\n",
            "781/781 [==============================] - 353s 451ms/step - loss: 1.6230 - acc: 0.7826 - val_loss: 2.8468 - val_acc: 0.5719\n",
            "\n",
            "Epoch 00002: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 3/10\n",
            "781/781 [==============================] - 457s 585ms/step - loss: 1.6255 - acc: 0.7824 - val_loss: 2.8791 - val_acc: 0.5673\n",
            "Epoch 4/10\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6312 - acc: 0.7813 - val_loss: 2.8730 - val_acc: 0.5676\n",
            "Epoch 5/10\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6284 - acc: 0.7815 - val_loss: 2.8486 - val_acc: 0.5732\n",
            "Epoch 6/10\n",
            "781/781 [==============================] - 457s 585ms/step - loss: 1.6220 - acc: 0.7823 - val_loss: 2.8460 - val_acc: 0.5739\n",
            "Epoch 7/10\n",
            "781/781 [==============================] - 458s 587ms/step - loss: 1.6241 - acc: 0.7837 - val_loss: 2.8225 - val_acc: 0.5786\n",
            "\n",
            "Epoch 00007: saving model to ../checkpoints/check.ckpt\n",
            "Epoch 8/10\n",
            "781/781 [==============================] - 461s 590ms/step - loss: 1.6232 - acc: 0.7823 - val_loss: 2.8650 - val_acc: 0.5694\n",
            "Epoch 9/10\n",
            "781/781 [==============================] - 460s 589ms/step - loss: 1.6262 - acc: 0.7833 - val_loss: 2.8623 - val_acc: 0.5672\n",
            "Epoch 10/10\n",
            "781/781 [==============================] - 460s 589ms/step - loss: 1.6218 - acc: 0.7839 - val_loss: 2.8422 - val_acc: 0.5724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff1101e3da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir3gMg7biil6",
        "colab_type": "text"
      },
      "source": [
        "## Achieved Validation Accuracy of 57.86 on Epoch 402\n",
        "\n",
        "---\n",
        "\n",
        "## Total Epochs = 405"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Rk_5_v7E2v",
        "colab_type": "text"
      },
      "source": [
        "### Tried this Hard Mining function but could'nt get it to work !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dvQOeXkD8-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import environ\n",
        "from keras.models import load_model\n",
        "batch_size = 64\n",
        "model = load_model(checkpoint_path)\n",
        "\n",
        "def mine_hard_samples(model, datagen, batch_size):\n",
        "   while True:\n",
        "       samples, targets = [], []\n",
        "       while len(samples) < batch_size:\n",
        "           x_data, y_data = next(datagen)\n",
        "           preds = model.predict(x_data)\n",
        "           \n",
        "           errors = np.abs(preds - y_data).max(axis=-1) > .99\n",
        "           \n",
        "           samples += x_data[errors].tolist()\n",
        "           targets += y_data[errors].tolist()\n",
        "\n",
        "       regular_samples = batch_size * 2 - len(samples)\n",
        "       x_data, y_data = next(datagen)\n",
        "       samples += x_data[:regular_samples].tolist()\n",
        "       targets += y_data[:regular_samples].tolist()\n",
        "\n",
        "       samples, targets = map(np.array, (samples, targets))\n",
        "\n",
        "       idx = np.arange(batch_size * 2)\n",
        "       np.random.shuffle(idx)\n",
        "       batch1, batch2 = np.split(idx, 2)\n",
        "       yield samples[batch1], targets[batch1]\n",
        "       yield samples[batch2], targets[batch2]\n",
        "\n",
        "def valid_main():\n",
        "   model = load_model(checkpoint_path)\n",
        "\n",
        "   x, y = next(train_generator)\n",
        "   model.predict(x)\n",
        "\n",
        "   model.fit_generator(mine_hard_samples(model, train_generator, 64),\n",
        "                       steps_per_epoch=100000 // 64, \n",
        "                       epochs=1)\n",
        "\n",
        "valid_main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEMKLeS2i5xe",
        "colab_type": "text"
      },
      "source": [
        "### List of references for easy lookup\n",
        "\n",
        "---\n",
        "\n",
        "1. Building blocks of interpretability: [Link](https://distill.pub/2018/building-blocks/) (Holy Grail of Intuition!)\n",
        "2. Deep Residual Learning for image classification: [Link](https://arxiv.org/abs/1512.03385) (Resnet Paper)\n",
        "3. Bag of tricks for image classification: [Link](https://arxiv.org/abs/1812.01187) (Tweaks and tricks to Resnet for increased performance paper)\n",
        "2. Imbalanced Deep Learning by Minority Class\n",
        "Incremental Rectification: [Link](https://arxiv.org/pdf/1804.10851.pdf) (Selectively Sampling Data paper)\n",
        "2. Improved Regularization of Convolutional Neural Networks with Cutout: [Link](https://arxiv.org/pdf/1708.04552.pdf) (Cutout/Occlusion Augmentation paper)\n",
        "3. Survey of resampling techniques for improving\n",
        "classification performance in unbalanced datasets [Link](https://arxiv.org/pdf/1608.06048v1.pdf) (Resampling paper)\n",
        "4. https://arxiv.org/pdf/1804.10851.pdf\n",
        "5. https://github.com/wpriyadarshani/Resampling_Techniques\n",
        "6.   https://www.researchgate.net/post/Machine_learning_if_proportion_of_number_of_cases_in_different_class_in_training_set_matters\n",
        "7. https://arxiv.org/pdf/1801.05365.pdf\n",
        "8. https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
        "9. https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/\n",
        "10. https://arxiv.org/pdf/1608.06048v1.pdf"
      ]
    }
  ]
}